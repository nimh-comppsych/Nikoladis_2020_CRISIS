{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import statsmodels.formula.api as smf\n",
    "import scipy as sp\n",
    "\n",
    "pd.set_option('max_rows', 400)\n",
    "pd.set_option('max_columns', 400)\n",
    "pd.set_option('max_colwidth', 500)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('../data')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make value luts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def make_lut(field, int_keys=True):\n",
    "    lut = {}\n",
    "    for ff in field.split('|'):\n",
    "        code = ff.split(', ')[0]\n",
    "        val = ff.replace(f'{code}, ', '').strip()\n",
    "        if int_keys:\n",
    "            lut[int(code)] = val\n",
    "        else:\n",
    "            lut[code.strip().lower()] = val\n",
    "    return lut\n",
    "\n",
    "defs_path = data_dir / 'CRISISAdultSelfReportBaselineP_DataDictionary_2020-04-18.csv'\n",
    "defs = pd.read_csv(defs_path)\n",
    "\n",
    "names_vals = defs.loc[defs['Choices, Calculations, OR Slider Labels'].notnull(),\n",
    "                     ['Variable / Field Name', 'Choices, Calculations, OR Slider Labels']]\n",
    "\n",
    "luts = {}\n",
    "for ix, row in names_vals.iterrows():\n",
    "    luts[row['Variable / Field Name']] = make_lut(row['Choices, Calculations, OR Slider Labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'Afghanistan',\n",
       " 2: 'Albania',\n",
       " 3: 'Algeria',\n",
       " 4: 'Andorra',\n",
       " 5: 'Angola',\n",
       " 6: 'Antigua and Barbuda',\n",
       " 7: 'Argentina',\n",
       " 8: 'Armenia',\n",
       " 9: 'Australia',\n",
       " 10: 'Austria',\n",
       " 11: 'Azerbaijan',\n",
       " 12: 'Bahamas',\n",
       " 13: 'Bahrain',\n",
       " 14: 'Bangladesh',\n",
       " 15: 'Barbados',\n",
       " 16: 'Belarus',\n",
       " 17: 'Belgium',\n",
       " 18: 'Belize',\n",
       " 19: 'Benin',\n",
       " 20: 'Bhutan',\n",
       " 21: 'Bolivia',\n",
       " 22: 'Bosnia and Herzegovina',\n",
       " 23: 'Botswana',\n",
       " 24: 'Brazil',\n",
       " 25: 'Brunei',\n",
       " 26: 'Bulgaria',\n",
       " 27: 'Burkina Faso',\n",
       " 28: 'Burundi',\n",
       " 29: \"Côte d'Ivoire\",\n",
       " 30: 'Cabo Verde',\n",
       " 31: 'Cambodia',\n",
       " 32: 'Cameroon',\n",
       " 33: 'Canada',\n",
       " 34: 'Central African Republic',\n",
       " 35: 'Chad',\n",
       " 36: 'Chile',\n",
       " 37: 'China',\n",
       " 38: 'Colombia',\n",
       " 39: 'Comoros',\n",
       " 40: 'Congo (Congo-Brazzaville)',\n",
       " 41: 'Costa Rica',\n",
       " 42: 'Croatia',\n",
       " 43: 'Cuba',\n",
       " 44: 'Cyprus',\n",
       " 45: 'Czechia (Czech Republic)',\n",
       " 46: 'Democratic Republic of the Congo',\n",
       " 47: 'Denmark',\n",
       " 48: 'Djibouti',\n",
       " 49: 'Dominica',\n",
       " 50: 'Dominican Republic',\n",
       " 51: 'Ecuador',\n",
       " 52: 'Egypt',\n",
       " 53: 'El Salvador',\n",
       " 54: 'Equatorial Guinea',\n",
       " 55: 'Eritrea',\n",
       " 56: 'Estonia',\n",
       " 57: 'Eswatini (fmr. \"Swaziland\")',\n",
       " 58: 'Ethiopia',\n",
       " 59: 'Fiji',\n",
       " 60: 'Finland',\n",
       " 61: 'France',\n",
       " 62: 'Gabon',\n",
       " 63: 'Gambia',\n",
       " 64: 'Georgia',\n",
       " 65: 'Germany',\n",
       " 66: 'Ghana',\n",
       " 67: 'Greece',\n",
       " 68: 'Grenada',\n",
       " 69: 'Guatemala',\n",
       " 70: 'Guinea',\n",
       " 71: 'Guinea-Bissau',\n",
       " 72: 'Guyana',\n",
       " 73: 'Haiti',\n",
       " 74: 'Holy See',\n",
       " 75: 'Honduras',\n",
       " 76: 'Hungary',\n",
       " 77: 'Iceland',\n",
       " 78: 'India',\n",
       " 79: 'Indonesia',\n",
       " 80: 'Iran',\n",
       " 81: 'Iraq',\n",
       " 82: 'Ireland',\n",
       " 83: 'Israel',\n",
       " 84: 'Italy',\n",
       " 85: 'Jamaica',\n",
       " 86: 'Japan',\n",
       " 87: 'Jordan',\n",
       " 88: 'Kazakhstan',\n",
       " 89: 'Kenya',\n",
       " 90: 'Kiribati',\n",
       " 91: 'Kuwait',\n",
       " 92: 'Kyrgyzstan',\n",
       " 93: 'Laos',\n",
       " 94: 'Latvia',\n",
       " 95: 'Lebanon',\n",
       " 96: 'Lesotho',\n",
       " 97: 'Liberia',\n",
       " 98: 'Libya',\n",
       " 99: 'Liechtenstein',\n",
       " 100: 'Lithuania',\n",
       " 101: 'Luxembourg',\n",
       " 102: 'Madagascar',\n",
       " 103: 'Malawi',\n",
       " 104: 'Malaysia',\n",
       " 105: 'Maldives',\n",
       " 106: 'Mali',\n",
       " 107: 'Malta',\n",
       " 108: 'Marshall Islands',\n",
       " 109: 'Mauritania',\n",
       " 110: 'Mauritius',\n",
       " 111: 'Mexico',\n",
       " 112: 'Micronesia',\n",
       " 113: 'Moldova',\n",
       " 114: 'Monaco',\n",
       " 115: 'Mongolia',\n",
       " 116: 'Montenegro',\n",
       " 117: 'Morocco',\n",
       " 118: 'Mozambique',\n",
       " 119: 'Myanmar (formerly Burma)',\n",
       " 120: 'Namibia',\n",
       " 121: 'Nauru',\n",
       " 122: 'Nepal',\n",
       " 123: 'Netherlands',\n",
       " 124: 'New Zealand',\n",
       " 125: 'Nicaragua',\n",
       " 126: 'Niger',\n",
       " 127: 'Nigeria',\n",
       " 128: 'North Korea',\n",
       " 129: 'North Macedonia',\n",
       " 130: 'Norway',\n",
       " 131: 'Oman',\n",
       " 132: 'Pakistan',\n",
       " 133: 'Palau',\n",
       " 134: 'Palestine State',\n",
       " 135: 'Panama',\n",
       " 136: 'Papua New Guinea',\n",
       " 137: 'Paraguay',\n",
       " 138: 'Peru',\n",
       " 139: 'Philippines',\n",
       " 140: 'Poland',\n",
       " 141: 'Portugal',\n",
       " 142: 'Qatar',\n",
       " 143: 'Romania',\n",
       " 144: 'Russia',\n",
       " 145: 'Rwanda',\n",
       " 146: 'Saint Kitts and Nevis',\n",
       " 147: 'Saint Lucia',\n",
       " 148: 'Saint Vincent and the Grenadines',\n",
       " 149: 'Samoa',\n",
       " 150: 'San Marino',\n",
       " 151: 'Sao Tome and Principe',\n",
       " 152: 'Saudi Arabia',\n",
       " 153: 'Senegal',\n",
       " 154: 'Serbia',\n",
       " 155: 'Seychelles',\n",
       " 156: 'Sierra Leone',\n",
       " 157: 'Singapore',\n",
       " 158: 'Slovakia',\n",
       " 159: 'Slovenia',\n",
       " 160: 'Solomon Islands',\n",
       " 161: 'Somalia',\n",
       " 162: 'South Africa',\n",
       " 163: 'South Korea',\n",
       " 164: 'South Sudan',\n",
       " 165: 'Spain',\n",
       " 166: 'Sri Lanka',\n",
       " 167: 'Sudan',\n",
       " 168: 'Suriname',\n",
       " 169: 'Sweden',\n",
       " 170: 'Switzerland',\n",
       " 171: 'Syria',\n",
       " 172: 'Tajikistan',\n",
       " 173: 'Tanzania',\n",
       " 174: 'Thailand',\n",
       " 175: 'Timor-Leste',\n",
       " 176: 'Togo',\n",
       " 177: 'Tonga',\n",
       " 178: 'Trinidad and Tobago',\n",
       " 179: 'Tunisia',\n",
       " 180: 'Turkey',\n",
       " 181: 'Turkmenistan',\n",
       " 182: 'Tuvalu',\n",
       " 183: 'Uganda',\n",
       " 184: 'Ukraine',\n",
       " 185: 'United Arab Emirates',\n",
       " 186: 'United Kingdom',\n",
       " 187: 'United States of America',\n",
       " 188: 'Uruguay',\n",
       " 189: 'Uzbekistan',\n",
       " 190: 'Vanuatu',\n",
       " 191: 'Venezuela',\n",
       " 192: 'Vietnam',\n",
       " 193: 'Yemen',\n",
       " 194: 'Zambia',\n",
       " 195: 'Zimbabwe'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "luts['country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_race_field = \"1, England, Ireland, Scotland or Wales | 2, Australia - not of Aboriginal or Torres Strait Islander descent | 3, Australia - of Aboriginal or Torres Strait Islander descent | 4, New Zealand - not of Maori descent | 5, New Zealand - of Maori descent | 6, Northern Europe including Sweden, Norway, Finland and surrounding countries | 7, Western Europe including France, Germany, the Netherlands and surrounding countries | 8, Southern Europe including Italy, Greece, Spain, Portugal and surrounding countries | 9, Eastern Europe including Russia, Poland, Hungary and surrounding countries | 10, Middle East including Lebanon, Turkey and surrounding countries | 11, Eastern Asia including China, Japan, South Korea, North Korea, Taiwan and Hong Kong | 12, South-East Asia including Thailand, Malaysia, Indonesia, Singapore and surrounding countries | 13, South Asia including India, Pakistan, Sri Lanka and surrounding countries | 14, Polynesia, Micronesia or Melanesia including Tonga, Fiji, Papua New Guinea and surrounding countries | 15, Africa | 16, North America - not of First Nations, Native American, Inuit or Métis descent | 17, North America - of First Nations, Native American, Inuit or Métis descent | Caribbean, Central or South America | 18, Don't know | 19, Other\"\n",
    "luts['parent_race'] = make_lut(parent_race_field, int_keys = False)\n",
    "luts['parent_race'].pop('caribbean')\n",
    "luts['parent_race']['caribbean'] = 'Caribbean, Central or South America'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"{1: 'England, Ireland, Scotland or Wales',\n",
    " 2: 'Australia - not of Aboriginal or Torres Strait Islander descent',\n",
    " 3: 'Australia - of Aboriginal or Torres Strait Islander descent',\n",
    " 4: 'New Zealand - not of Maori descent',\n",
    " 5: 'New Zealand - of Maori descent',\n",
    " 6: 'Northern Europe including Sweden, Norway, Finland and surrounding countries',\n",
    " 7: 'Western Europe including France, Germany, the Netherlands and surrounding countries',\n",
    " 8: 'Eastern Europe including Russia, Poland, Hungary and surrounding countries',\n",
    " 9: 'Southern Europe including Italy, Greece, Spain, Portugal and surrounding countries',\n",
    " 10: 'Middle East including Lebanon, Turkey and surrounding countries',\n",
    " 11: 'Eastern Asia including China, Japan, South Korea, North Korea, Taiwan and Hong Kong',\n",
    " 12: 'South-East Asia including Thailand, Malaysia, Indonesia, Singapore and surrounding countries',\n",
    " 13: 'South Asia including India, Pakistan, Sri Lanka and surrounding countries',\n",
    " 14: 'Polynesia, Micronesia or Melanesia including Tonga, Fiji, Papua New Guinea and surrounding countries',\n",
    " 15: 'Africa',\n",
    " 16: 'North America - not of First Nations, Native American, Inuit or Métis descent',\n",
    " 17: 'North America - of First Nations, Native American, Inuit or Métis descent',\n",
    " 18: 'Caribbean, Central or South America',\n",
    " 19: \"Don't know\",\n",
    " 20: 'Other'}\"\"\"\n",
    "\n",
    "us_ances_lut =   {1: 'White',\n",
    "                 2: 'White',\n",
    "                 3: 'Other',\n",
    "                 4: 'White',\n",
    "                 5: 'Other',\n",
    "                 6: 'White', \n",
    "                 7: 'White', \n",
    "                 8: 'White', \n",
    "                 9: 'White', \n",
    "                 10: 'Middle Eastern',\n",
    "                 11: 'South-East Asian',\n",
    "                 12: 'South-East Asian', \n",
    "                 13: 'South Asian', \n",
    "                 14: 'Other', \n",
    "                 15: 'Africa', \n",
    "                 16: 'White', \n",
    "                 17: 'North American', \n",
    "                 18: 'Caribbean, Central or South America',\n",
    "                 19: \"Don't Know\", \n",
    "                 20: 'Other'}\n",
    "\n",
    "uk_ances_lut =   {1: 'British',\n",
    "                 2: 'White',\n",
    "                 3: 'Other',\n",
    "                 4: 'White',\n",
    "                 5: 'Other',\n",
    "                 6: 'White', \n",
    "                 7: 'White', \n",
    "                 8: 'White', \n",
    "                 9: 'White', \n",
    "                 10: 'Middle Eastern',\n",
    "                 11: 'South-East Asian',\n",
    "                 12: 'South-East Asian', \n",
    "                 13: 'South Asian', \n",
    "                 14: 'Other', \n",
    "                 15: 'Africa', \n",
    "                 16: 'White', \n",
    "                 17: 'North American', \n",
    "                 18: 'Caribbean, Central or South America',\n",
    "                 19: \"Don't Know\", \n",
    "                 20: 'Other'}\n",
    "pa_ances_lut = {1: 'White',\n",
    "                 2: 'White',\n",
    "                 3: 'Other',\n",
    "                 4: 'White',\n",
    "                 5: 'Other',\n",
    "                 6: 'White', \n",
    "                 7: 'White', \n",
    "                 8: 'White', \n",
    "                 9: 'White', \n",
    "                 10: 'Asian',\n",
    "                 11: 'Asian',\n",
    "                 12: 'Asian', \n",
    "                 13: 'Asian', \n",
    "                 14: 'Other', \n",
    "                 15: 'Black', \n",
    "                 16: 'White', \n",
    "                 17: 'Other', \n",
    "                 18: 'White',\n",
    "                 19: 'Other', \n",
    "                 20: 'Other'}\n",
    "ances_luts = {'US':us_ances_lut, 'UK':uk_ances_lut, 'PA':pa_ances_lut}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ances_col(df, alut, lut_name='race_cat'):\n",
    "    df = df.copy()\n",
    "    cats = np.unique(list(alut.values()))\n",
    "    reverse_lut = {aa:[] for aa in cats}\n",
    "    for k, v in alut.items():\n",
    "        for aa in cats:\n",
    "            if v == aa:\n",
    "                reverse_lut[aa].append(f'raceethnicity___{k}')\n",
    "    for aa in cats:\n",
    "        df[aa] = df.loc[:, reverse_lut[aa]].sum(1) >=1\n",
    "    df['Mixed'] = df.loc[:, cats].sum(1) > 1\n",
    "    df.loc[df.Mixed, cats] = False\n",
    "\n",
    "    df['no_race'] = False\n",
    "    df.loc[df.loc[:, cats].sum(1) == 0, 'no_race'] = True\n",
    "\n",
    "    df['race_cat'] = 'no_race'\n",
    "    for aa in cats:\n",
    "        df.loc[df[aa], lut_name] = aa\n",
    "    df.loc[df.Mixed] ='Mixed' \n",
    "    return df[lut_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get demographic dists for each form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "usadult_path = data_dir / 'Adult_US.csv'\n",
    "usparent_path = data_dir / 'Parent_US.csv'\n",
    "ukadult_path = data_dir / 'Adult_UK.csv'\n",
    "uktrt_path = data_dir / 'Adult_UK_RT.csv'\n",
    "ukparent_path = data_dir / 'Parent_UK.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "usa = pd.read_csv(usadult_path)\n",
    "usa['sample_country'] = 'US'\n",
    "usa['source_file'] = usadult_path.parts[-1]\n",
    "usa = usa.rename(columns={'Sample': 'sample'})\n",
    "\n",
    "usp = pd.read_csv(usparent_path)\n",
    "usp['sample_country'] = 'US'\n",
    "usp['source_file'] = usparent_path.parts[-1]\n",
    "\n",
    "uka = pd.read_csv(ukadult_path)\n",
    "uka['sample_country'] = 'UK'\n",
    "uka['source_file'] = ukadult_path.parts[-1]\n",
    "\n",
    "ukp = pd.read_csv(ukparent_path)\n",
    "ukp['sample_country'] = 'UK'\n",
    "ukp['source_file'] = ukparent_path.parts[-1]\n",
    "\n",
    "ukr = pd.read_csv(uktrt_path)\n",
    "ukr['sample_country'] = 'UK'\n",
    "ukr['source_file'] = uktrt_path.parts[-1]\n",
    "\n",
    "adat = pd.concat([usa, uka, ukr], sort=False, ignore_index=True)\n",
    "pdat = pd.concat([usp, ukp], sort=False, ignore_index=True)\n",
    "# Fix the race columns in the parent data\n",
    "pdat['raceethnicity___20'] = pdat.raceethnicity___19\n",
    "pdat['raceethnicity___19'] = pdat.raceethnicity___18\n",
    "pdat['raceethnicity___18'] = pdat.raceethnicity___caribbean\n",
    "pdat = pdat.drop('raceethnicity___caribbean', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deal with age_cat then we can merge\n",
    "adat['age_cat'] = 'no_age'\n",
    "adat.loc[adat.years < 18, 'age_cat'] = '< 18'\n",
    "adat.loc[(adat.years >= 18) & (adat.years <= 27) , 'age_cat'] = '18-27'\n",
    "adat.loc[(adat.years >= 28) & (adat.years <= 37) , 'age_cat'] = '28-37'\n",
    "adat.loc[(adat.years >= 38) & (adat.years <= 47) , 'age_cat'] = '38-47'\n",
    "adat.loc[(adat.years >= 48) & (adat.years <= 57) , 'age_cat'] = '48-57'\n",
    "adat.loc[(adat.years >= 58), 'age_cat'] = '58+'\n",
    "\n",
    "pdat['age_cat'] = 'no_age'\n",
    "pdat.loc[pdat.years_2 <= 5, 'age_cat'] = '<= 5'\n",
    "pdat.loc[(pdat.years_2 >= 6) & (pdat.years_2 <= 10) , 'age_cat'] = '6-10'\n",
    "pdat.loc[(pdat.years_2 >= 11) & (pdat.years_2 <= 15) , 'age_cat'] = '11-15'\n",
    "pdat.loc[(pdat.years_2 >= 15), 'age_cat'] = '15+'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge parent and adult\n",
    "dat = pd.concat([adat, pdat], sort=False, ignore_index=True)\n",
    "assert dat.index.nunique() == len(dat)\n",
    "dat = dat.reset_index()\n",
    "dat['uid'] = dat.participant_id+dat['index'].apply(lambda x: f'_{x:05d}')\n",
    "dat = dat.drop('index', axis=1)\n",
    "dat['country_name'] = dat.loc[dat.country.notnull(), 'country'].apply(lambda x: luts['country'][x])\n",
    "dat.loc[dat.country_name == 'United States of America', 'country_name'] = 'US'\n",
    "dat.loc[dat.timestamp1.isnull(), 'timestamp1'] = dat.loc[dat.timestamp1.isnull(), 'timestamp2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sex category\n",
    "dat['sex_cat'] = 'no_sex'\n",
    "dat.loc[dat.sex == 1, 'sex_cat'] = 'Male'\n",
    "dat.loc[dat.sex == 2, 'sex_cat'] = 'Female'\n",
    "dat.loc[dat.sex == 3, 'sex_cat'] = 'Other'\n",
    "\n",
    "# Make race category\n",
    "dat['race_cat'] = np.nan\n",
    "dat.loc[dat.sample_country == 'US', 'race_cat'] = make_ances_col(dat.loc[dat.sample_country == 'US'], us_ances_lut)\n",
    "dat.loc[dat.sample_country == 'UK', 'race_cat'] = make_ances_col(dat.loc[dat.sample_country == 'UK'], uk_ances_lut)\n",
    "dat['PA_race_cat'] = make_ances_col(dat, pa_ances_lut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_counts = (dat.groupby('sample')[['participant_id']]\n",
    "               .count()\n",
    "               .rename(columns={'participant_id': 'sample_n'})\n",
    "               .reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_nums = (dat.groupby(['sample', 'sex_cat'])[['participant_id']]\n",
    "            .count()\n",
    "            .rename(columns={'participant_id': 'cat_n'})\n",
    "            .reset_index()\n",
    "            .merge(samp_counts, how='left', on='sample'))\n",
    "sex_nums['cat_prop'] = sex_nums.cat_n / sex_nums.sample_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_nums = (dat.groupby(['sample', 'age_cat'])[['participant_id']]\n",
    "            .count()\n",
    "            .rename(columns={'participant_id': 'cat_n'})\n",
    "            .reset_index()\n",
    "            .merge(samp_counts, how='left', on='sample'))\n",
    "age_nums['cat_prop'] = age_nums.cat_n / age_nums.sample_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_nums = (dat.groupby(['sample', 'race_cat'])[['participant_id']]\n",
    "            .count()\n",
    "            .rename(columns={'participant_id': 'cat_n'})\n",
    "            .reset_index()\n",
    "            .merge(samp_counts, how='left', on='sample'))\n",
    "race_nums['cat_prop'] = race_nums.cat_n / race_nums.sample_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "race_nums.loc[:, ['sample', 'sample_n', 'race_cat', 'cat_n', 'cat_prop']].sort_values(['sample', 'cat_n'], ascending=[True, False]).to_csv(data_dir/'race_breakdown.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make exclude column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Adult_US', 'Adult_US_CA', 'Adult_US_NY', 'Adult_US_RT',\n",
       "       'Adult_London', 'Adult_Manchester', 'Adult_UK', 'Adult_UK_RT',\n",
       "       'Parent_US', 'Parent_US_RT', 'Parent_US_CA', 'Parent_US_NY',\n",
       "       'Parent_UK', 'Parent_UK_London', 'Parent_UK_Manchester',\n",
       "       'Parent_UK_RT'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat['sample'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_samples = ['Adult_US', 'Adult_US_CA', 'Adult_US_NY', 'Adult_US_RT',\n",
    "                 'Adult_London', 'Adult_Manchester', 'Adult_UK', 'Adult_UK_RT']\n",
    "parent_samples = ['Parent_US', 'Parent_US_RT', 'Parent_US_CA', 'Parent_US_NY',\n",
    "                  'Parent_UK', 'Parent_UK_London', 'Parent_UK_Manchester',\n",
    "                  'Parent_UK_RT']\n",
    "rt_samples = [\"Adult_US_RT\", \"Adult_UK_RT\", 'Parent_US_RT', 'Parent_UK_RT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "adat = dat.loc[dat['sample'].isin(adult_samples)]\n",
    "pdat = dat.loc[dat['sample'].isin(parent_samples)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>samples</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Adult_US_CA, Adult_US_NY</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adult_London, Adult_UK</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Adult_US_CA, Adult_US_CA, Adult_US_NY, Adult_US_NY</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adult_London, Adult_London</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adult_US, Adult_US</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Adult_US, Adult_US, Adult_US, Adult_US</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Adult_US, Adult_US, Adult_US_NY, Adult_US_NY</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Adult_US, Adult_US_NY</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Adult_US, Adult_US_CA</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adult_London, Adult_UK, Adult_UK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adult_Manchester, Adult_UK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Adult_US, Adult_US, Adult_US, Adult_US_CA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Adult_US, Adult_US_CA, Adult_US_CA, Adult_US_NY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Adult_US, Adult_US_CA, Adult_US_NY, Adult_US_NY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               samples  counts\n",
       "13                            Adult_US_CA, Adult_US_NY      20\n",
       "1                               Adult_London, Adult_UK      15\n",
       "12  Adult_US_CA, Adult_US_CA, Adult_US_NY, Adult_US_NY      11\n",
       "0                           Adult_London, Adult_London       5\n",
       "4                                   Adult_US, Adult_US       4\n",
       "5               Adult_US, Adult_US, Adult_US, Adult_US       4\n",
       "7         Adult_US, Adult_US, Adult_US_NY, Adult_US_NY       3\n",
       "11                               Adult_US, Adult_US_NY       3\n",
       "8                                Adult_US, Adult_US_CA       2\n",
       "2                     Adult_London, Adult_UK, Adult_UK       1\n",
       "3                           Adult_Manchester, Adult_UK       1\n",
       "6            Adult_US, Adult_US, Adult_US, Adult_US_CA       1\n",
       "9      Adult_US, Adult_US_CA, Adult_US_CA, Adult_US_NY       1\n",
       "10     Adult_US, Adult_US_CA, Adult_US_NY, Adult_US_NY       1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "artdat = adat.loc[adat['sample'].isin(rt_samples) & (adat.adult_selfreport_baseline_form_complete == 2), :]\n",
    "asdat = adat.loc[~adat['sample'].isin(rt_samples) & (adat.adult_selfreport_baseline_form_complete == 2), :]\n",
    "prtdat = pdat.loc[pdat['sample'].isin(rt_samples) & (pdat.parentcaregiver_baseline_form_complete == 2), :]\n",
    "psdat = pdat.loc[~pdat['sample'].isin(rt_samples) & (pdat.parentcaregiver_baseline_form_complete == 2), :]\n",
    "\n",
    "# There are duplicated participant IDS\n",
    "# Some duplications are ok (Parent + Adult), potentially parent + parent if they have more than one kid\n",
    "# First we'll split out adult sample and look for duplications there\n",
    "multi_sample_ids = asdat.groupby(\"participant_id\")[['sample']].count().sort_values('sample', ascending=False).reset_index().query(\"sample > 1\").participant_id\n",
    "# display(asdat.groupby(\"participant_id\")[['sample']].count().sort_values('sample', ascending=False).reset_index().groupby(\"sample\").count())\n",
    "\n",
    "\n",
    "dups = []\n",
    "for id,df in asdat.loc[asdat.participant_id.isin(multi_sample_ids), :].groupby('participant_id'):\n",
    "    dups.append(', '.join(list(sorted(df['sample'].values))))\n",
    "    \n",
    "samples, counts = np.unique(dups, return_counts=True)\n",
    "\n",
    "dup_table = pd.DataFrame()\n",
    "dup_table['samples'] = samples\n",
    "dup_table['counts'] = counts\n",
    "display(dup_table.sort_values('counts', ascending=False))\n",
    "\n",
    "field_difs = []\n",
    "for id,df in asdat.loc[asdat.participant_id.isin(multi_sample_ids), :].groupby('participant_id'):\n",
    "    uniques = df.nunique()\n",
    "    uniques = pd.DataFrame(uniques[uniques > 1], columns=['n_unique_vals'])\n",
    "    uniques = uniques.drop(['uid', 'sample', 'timestamp1', 'timestamp2'], errors = 'ignore')\n",
    "    if len(uniques) == 0:\n",
    "        continue\n",
    "    uniques = uniques.T\n",
    "    uniques['participant_id'] = id\n",
    "    field_difs.append(uniques)\n",
    "dif_resp_ids = pd.concat(field_difs, ignore_index=True, sort=False).participant_id\n",
    "\n",
    "# display(asdat.query('participant_id.isin(@dif_resp_ids)').sort_values('participant_id'))\n",
    "\n",
    "ps_multi_sample_ids = psdat.groupby(\"participant_id\")[['sample']].count().sort_values('sample', ascending=False).reset_index().query(\"sample > 1\").participant_id\n",
    "#psdat.groupby(\"participant_id\")[['sample']].count().sort_values('sample', ascending=False).reset_index().groupby(\"sample\").count()\n",
    "# print(\"parent report data\")\n",
    "# display(psdat.loc[psdat.participant_id.isin(ps_multi_sample_ids), :].sort_values('participant_id'))\n",
    "\n",
    "# psdat.loc[psdat.participant_id.isin(ps_multi_sample_ids), :].sort_values('participant_id').uid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adult_duped_ids = multi_sample_ids[~multi_sample_ids.isin(dif_resp_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dupe_pick_ind =  (dat.participant_id.isin(adult_duped_ids)\n",
    "                 & (dat.adult_selfreport_baseline_form_complete != 0)\n",
    "                 & (dat.parentcaregiver_baseline_form_complete != 0))\n",
    "keep_resps = dat.loc[dupe_pick_ind, :].sort_values('timestamp1').groupby('participant_id').first().uid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     59d65d404f19050001763c39\n",
       "1     5abc50b2f69e940001d92a87\n",
       "2     5b7ba81916aa44000169aa2f\n",
       "3     5b9c270f12dc2f0001ac933e\n",
       "4     5c6d460ec3aa150001145611\n",
       "5     5c6f9453cbd1430001a04463\n",
       "6     5d4c4fadb2adbc0001fcbcfc\n",
       "7     5d58557e7e527000158ec316\n",
       "8     5d8312e5d1893500011f80ba\n",
       "9     5da6c887897c0e0014528d3b\n",
       "10    5dd66c10f83c9f5ef3a7bc0b\n",
       "11    5e0857276aab7c17f7e21662\n",
       "12    5e3f7b63badc6c1db1be6647\n",
       "13    5e4c2ab748843608239fd84d\n",
       "14    5e5d04c154c9ac000bf350bd\n",
       "15    5e64393b2a0d161c7c02126c\n",
       "16    5e83e82e30500a14da61c864\n",
       "17    5e8480f48e665402a4109dfd\n",
       "18    5e87f838e770eb481802a443\n",
       "19    5e89ad187ad752640e558c8a\n",
       "20    5e90c2a79422bb3f36472444\n",
       "Name: participant_id, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dif_resp_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['exclude'] = False\n",
    "exclude_ind = ((dat.participant_id.isin(dif_resp_ids) & dat['sample'].isin(['Adult_US', 'Adult_US_CA', 'Adult_US_NY','Adult_London', 'Adult_Manchester', 'Adult_UK']))\n",
    "               | (dat.adult_selfreport_baseline_form_complete == 0)\n",
    "               | (dat.parentcaregiver_baseline_form_complete == 0)\n",
    "               | (dat.participant_id.isin(adult_duped_ids) & ~dat.uid.isin(keep_resps))\n",
    "               # Second entry about the same kid, keeping the first, which is 5a49d6a06d85f80001c25bc4_03615\n",
    "               | (dat.uid == '5a49d6a06d85f80001c25bc4_03614')\n",
    "              )\n",
    "dat.loc[exclude_ind, 'exclude'] = True\n",
    "\n",
    "# Exclude all instances of test-retest subjects outside the test retest data\n",
    "rt_dat = dat.loc[dat['sample'].isin(rt_samples), 'participant_id']\n",
    "dat.loc[dat.participant_id.isin(rt_dat) & ~dat['sample'].isin(rt_samples), 'exclude'] = True\n",
    "\n",
    "dat['form'] = np.nan\n",
    "dat.loc[dat['sample'].isin(adult_samples), 'form'] = 'adult'\n",
    "dat.loc[dat['sample'].isin(parent_samples), 'form'] = 'parent'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n",
      "151\n",
      "131\n",
      "75\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "print(((dat.participant_id.isin(dif_resp_ids)) & dat['sample'].isin(['Adult_US', 'Adult_US_CA', 'Adult_US_NY','Adult_London', 'Adult_Manchester', 'Adult_UK'])).sum())\n",
    "print((dat.adult_selfreport_baseline_form_complete == 0).sum())\n",
    "print((dat.parentcaregiver_baseline_form_complete == 0).sum())\n",
    "print((dat.participant_id.isin(adult_duped_ids) & ~dat.uid.isin(keep_resps)).sum())\n",
    "print((dat.participant_id.isin(rt_dat) & ~dat['sample'].isin(rt_samples)).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude all instances of test-retest subjects outside the test retest data\n",
    "rt_dat = dat.loc[dat['sample'].isin(rt_samples), 'participant_id']\n",
    "dat.loc[dat.participant_id.isin(rt_dat) & ~dat['sample'].isin(rt_samples), 'exclude'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['form'] = np.nan\n",
    "dat.loc[dat['sample'].isin(adult_samples), 'form'] = 'adult'\n",
    "dat.loc[dat['sample'].isin(parent_samples), 'form'] = 'parent'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure that we've really deduped the samples\n",
    "assert len(dat.loc[(~dat.exclude) & (~dat['sample'].isin(rt_samples)), :].groupby(['form', 'participant_id'])[['sample']].count().reset_index().query('sample > 1')) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merge in Diana's exclusion rules\n",
    "Also create a hash_dup_id column that's based on a hash of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dat = dat.copy(deep=True)\n",
    "\n",
    "dex_data = pd.read_csv(data_dir / 'data_with_exclusions_from_Diana.csv')\n",
    "\n",
    "# Fix some issues in the data\n",
    "trucated_cols = {'adult_selfreport_baseline_form_c': 'adult_selfreport_baseline_form_complete',\n",
    "                 'parentcaregiver_baseline_form_co': 'parentcaregiver_baseline_form_complete'}\n",
    "dex_data = dex_data.rename(columns=trucated_cols)\n",
    "\n",
    "pind = dex_data.raceethnicity___20.isnull() & dex_data.raceethnicity___caribbean.notnull() \n",
    "dex_data.loc[pind, 'raceethnicity___20'] = dex_data.loc[pind, 'raceethnicity___19']\n",
    "dex_data.loc[pind, 'raceethnicity___19'] = dex_data.loc[pind, 'raceethnicity___18']\n",
    "dex_data.loc[pind, 'raceethnicity___18'] = dex_data.loc[pind, 'raceethnicity___caribbean']\n",
    "\n",
    "# Stata screws up float representations due to flointing point\n",
    "dex_data['tall'] = np.round(dex_data.tall, 2)\n",
    "dex_data['weight'] = np.round(dex_data.weight, 2)\n",
    "tmp_dat['tall'] = np.round(tmp_dat.tall, 2)\n",
    "tmp_dat['weight'] = np.round(tmp_dat.weight, 2)\n",
    "\n",
    "# There's one case with a missing first timestamp where I loaded it from timestamp2\n",
    "dex_data.loc[dex_data.timestamp1.isnull(), 'timestamp1'] = dex_data.loc[dex_data.timestamp1.isnull(), 'timestamp2']\n",
    "\n",
    "md5_cols = ['participant_id',\n",
    "'sample',\n",
    "'timestamp1',\n",
    "'country',\n",
    "'stateetc',\n",
    "'county',\n",
    "'city',\n",
    "'years',\n",
    "'sex',\n",
    "'sex_other',\n",
    "'raceethnicity___1',\n",
    "'raceethnicity___2',\n",
    "'raceethnicity___3',\n",
    "'raceethnicity___4',\n",
    "'raceethnicity___5',\n",
    "'raceethnicity___6',\n",
    "'raceethnicity___7',\n",
    "'raceethnicity___8',\n",
    "'raceethnicity___9',\n",
    "'raceethnicity___10',\n",
    "'raceethnicity___11',\n",
    "'raceethnicity___12',\n",
    "'raceethnicity___13',\n",
    "'raceethnicity___14',\n",
    "'raceethnicity___15',\n",
    "'raceethnicity___16',\n",
    "'raceethnicity___17',\n",
    "'raceethnicity___18',\n",
    "'raceethnicity___19',\n",
    "'raceethnicity___20',\n",
    "'hispanic',\n",
    "'working___1',\n",
    "'working___2',\n",
    "'working___3',\n",
    "'working___4',\n",
    "'working___5',\n",
    "'working___6',\n",
    "'working___7',\n",
    "'working___8',\n",
    "'occupation',\n",
    "'military',\n",
    "'location',\n",
    "'education',\n",
    "'educationmother',\n",
    "'educationfather',\n",
    "'householdnumber',\n",
    "'essentialworkers',\n",
    "'essentialworkerhome',\n",
    "'covidfacility',\n",
    "'householdcomp___1',\n",
    "'householdcomp___2',\n",
    "'householdcomp___3',\n",
    "'householdcomp___4',\n",
    "'householdcomp___5',\n",
    "'householdcomp___6',\n",
    "'householdcomp___7',\n",
    "'roomsinhouse',\n",
    "'insurance',\n",
    "'govassist',\n",
    "'physicalhealth',\n",
    "'healthconditions___1',\n",
    "'healthconditions___2',\n",
    "'healthconditions___3',\n",
    "'healthconditions___4',\n",
    "'healthconditions___5',\n",
    "'healthconditions___6',\n",
    "'healthconditions___7',\n",
    "'healthconditions___8',\n",
    "'healthconditions___9',\n",
    "'healthconditions___10',\n",
    "'healthconditions___11',\n",
    "'healthconditions___12',\n",
    "'healthconditions___13',\n",
    "'healthconditions___14',\n",
    "'healthconditions___15',\n",
    "'healthconditions___16',\n",
    "'healthconditions___17',\n",
    "'tall',\n",
    "'measurementheight',\n",
    "'weight',\n",
    "'measurementweight',\n",
    "'mentalhealth',\n",
    "'exposed___1',\n",
    "'exposed___2',\n",
    "'exposed___3',\n",
    "'exposed___4',\n",
    "'infected',\n",
    "'symptoms___1',\n",
    "'symptoms___2',\n",
    "'symptoms___3',\n",
    "'symptoms___4',\n",
    "'symptoms___5',\n",
    "'symptoms___6',\n",
    "'symptoms___7',\n",
    "'symptoms___8',\n",
    "'othersymptoms',\n",
    "'diagnosedfamily___1',\n",
    "'diagnosedfamily___2',\n",
    "'diagnosedfamily___3',\n",
    "'impact___1',\n",
    "'impact___2',\n",
    "'impact___3',\n",
    "'impact___4',\n",
    "'impact___5',\n",
    "'impact___6',\n",
    "'impact___7',\n",
    "'impact___8',\n",
    "'worriedyourself',\n",
    "'worriedothers',\n",
    "'worriedphysical',\n",
    "'worriedmental',\n",
    "'readingtalking',\n",
    "'positivechange',\n",
    "'specifypositive',\n",
    "'schoolclosed',\n",
    "'classesinsession',\n",
    "'classesirl',\n",
    "'onlineclasses',\n",
    "'internetcompacess',\n",
    "'assignments',\n",
    "'mealsfromschool',\n",
    "'work',\n",
    "'goingtoworkplace',\n",
    "'workfromhome',\n",
    "'laidoff',\n",
    "'losejob',\n",
    "'inpersonconvo',\n",
    "'timeoutside',\n",
    "'restrictionsstress',\n",
    "'contactschanged',\n",
    "'difficultydistancing',\n",
    "'familychange',\n",
    "'familychangestress',\n",
    "'friendschange',\n",
    "'friendchangestress',\n",
    "'difficultycancellations',\n",
    "'financedifficulty',\n",
    "'livingdifficulty',\n",
    "'foodsecurity',\n",
    "'hopefullyend',\n",
    "'bedtimeweekdays',\n",
    "'bedtimeweekends',\n",
    "'hoursofsleepweekdays',\n",
    "'hoursofsleepweekends',\n",
    "'exerciseprior',\n",
    "'outdoorsprior',\n",
    "'priorworry',\n",
    "'priorhappyvssad',\n",
    "'priorenjoyactivities',\n",
    "'priorrelaxedvsanxious',\n",
    "'priorfidget',\n",
    "'priorfatigue',\n",
    "'priorfocus',\n",
    "'priorirritable',\n",
    "'priorlonely',\n",
    "'priornegthoughts',\n",
    "'priortvmedia',\n",
    "'priorsocialmedia',\n",
    "'priorvideogames',\n",
    "'threemonthsalcohol',\n",
    "'threemonthsvaping',\n",
    "'threemonthstobacco',\n",
    "'threemonthsmarijuana',\n",
    "'threemonthsopiates',\n",
    "'threemonthsother',\n",
    "'threemonthssleepingmeds',\n",
    "'bedtimeweekdays_2',\n",
    "'bedtimeweekends_2',\n",
    "'hoursofsleepweekdays_2',\n",
    "'hoursofsleepweekends_2',\n",
    "'exerciseprior_2',\n",
    "'outdoorsprior_2',\n",
    "'priorworry_2',\n",
    "'priorhappyvssad_2',\n",
    "'priorenjoyactivities_2',\n",
    "'priorrelaxedvsanxious_2',\n",
    "'priorfidget_2',\n",
    "'priorfatigue_2',\n",
    "'priorfocus_2',\n",
    "'priorirritable_2',\n",
    "'priorlonely_2',\n",
    "'priornegthoughts_2',\n",
    "'priortvmedia_2',\n",
    "'priorsocialmedia_2',\n",
    "'priorvideogames_2',\n",
    "'twoweeksalcohol',\n",
    "'twoweeksvaping',\n",
    "'twoweekstobacco',\n",
    "'twoweeksmarijuana',\n",
    "'twoweeksopiates',\n",
    "'twoweeksother',\n",
    "'twoweeksleeping',\n",
    "'disruptedsupports___1',\n",
    "'disruptedsupports___2',\n",
    "'disruptedsupports___3',\n",
    "'disruptedsupports___4',\n",
    "'disruptedsupports___5',\n",
    "'disruptedsupports___6',\n",
    "'disruptedsupports___7',\n",
    "'disruptedsupports___8',\n",
    "'disruptedsupports___9',\n",
    "'disruptedsupports___10',\n",
    "'disruptedsupports___11',\n",
    "'disruptedsupports___12',\n",
    "'disruptedsupports___13',\n",
    "'disruptedsupportsother',\n",
    "'anything_else',\n",
    "'timestamp2',\n",
    "'adult_selfreport_baseline_form_complete',\n",
    "'years_2',\n",
    "'caregiverrelation',\n",
    "'othercaregiverrelation',\n",
    "'school___1',\n",
    "'school___2',\n",
    "'school___3',\n",
    "'school___4',\n",
    "'school___5',\n",
    "'school___6',\n",
    "'parenteducation',\n",
    "'secondparenteducation',\n",
    "'priorweekdaybedtime',\n",
    "'priorweekendbedtime',\n",
    "'priorhoursofsleepweekdays',\n",
    "'priorhoursofsleepweekend',\n",
    "'priorweekdaybedtime_2',\n",
    "'priorweekendbedtime_2',\n",
    "'parentcaregiver_baseline_form_complete']\n",
    "md5_cols = pd.Series(md5_cols)\n",
    "\n",
    "dex_data['hash'] = dex_data.loc[:, md5_cols].apply(lambda x: hash(tuple(x)), axis=1)\n",
    "tmp_dat['hash'] = tmp_dat.loc[:, md5_cols].apply(lambda x: hash(tuple(x)), axis=1)\n",
    "\n",
    "assert (~tmp_dat.hash.isin(dex_data.hash)).sum() == 0\n",
    "# These are useful if this assert fails:\n",
    "# dat[~dat.hash.isin(dex_data.hash)]\n",
    "# pid = '5aeb6f1e23e2ca0001974556'\n",
    "# mismatches = dat.loc[dat.participant_id == pid, md5_cols].reset_index(drop=True) == dex_data.loc[dex_data.participant_id == pid, md5_cols].reset_index(drop=True)\n",
    "# dat.loc[dat.participant_id == pid, mismatches.loc[:, ~mismatches.loc[0]].columns]\n",
    "# dex_data.loc[dex_data.participant_id == pid, mismatches.loc[:, ~mismatches.loc[0]].columns]\n",
    "\n",
    "dex_data['dup_id'] = dex_data.groupby('hash').hash.apply(lambda x: np.argsort(x))\n",
    "dex_data['hash_dup_id'] = dex_data.hash.astype(str) + '_' + dex_data.dup_id.astype(str)\n",
    "\n",
    "tmp_dat['dup_id'] = tmp_dat.groupby('hash').hash.apply(lambda x: np.argsort(x))\n",
    "tmp_dat['hash_dup_id'] = tmp_dat.hash.astype(str) + '_' + tmp_dat.dup_id.astype(str)\n",
    "\n",
    "dex_merge = dex_data.loc[:, ['hash_dup_id', 'regsam','retest','duptag','dupsel']]\n",
    "\n",
    "td_len = len(tmp_dat)\n",
    "tmp_dat = tmp_dat.merge(dex_merge, on='hash_dup_id', how='left', indicator=True)\n",
    "assert tmp_dat.groupby('_merge').participant_id.count()['left_only'] == 0\n",
    "assert tmp_dat.groupby('_merge').participant_id.count()['right_only'] == 0\n",
    "tmp_dat = tmp_dat.drop('_merge', axis=1)\n",
    "\n",
    "assert td_len == len(tmp_dat)\n",
    "\n",
    "dat = dat.merge(tmp_dat.loc[:, ['uid', 'hash_dup_id', 'regsam','retest', 'duptag', 'dupsel']], on='uid', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dex_data = dex_data.merge(tmp_dat.loc[:, ['hash_dup_id', 'uid']], on='hash_dup_id')\n",
    "dex_data.to_csv(data_dir / 'data_with_exclusions_from_Diana_with_uid.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pick hold out sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data that has already been explored to make sure that they are not in the hold out\n",
    "xp_dat = pd.read_csv(data_dir / 'exploratory_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_ind = (~dat.exclude) & (~dat.participant_id.isin(rt_dat)) & (~dat.participant_id.isin(xp_dat.participant_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['hispanic_cat'] = dat.hispanic.fillna('no_response')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_ns = (dat.loc[holdout_ind, :]\n",
    "              .groupby(['sample', 'sex_cat', 'age_cat', 'race_cat', 'hispanic_cat'])[['participant_id']].count())\n",
    "# We've already excluded 1/6 because they're exploratory, so 2/5 of the remaining 5/6 is 1/3\n",
    "holdout_ns *= 2/5\n",
    "holdout_ns = holdout_ns.rename(columns={'participant_id': 'ho_n_prob'}).reset_index()\n",
    "holdout_ns['cutoff'] = holdout_ns.ho_n_prob % 1\n",
    "np.random.seed(0)\n",
    "holdout_ns['roll'] = np.random.uniform(size=len(holdout_ns))\n",
    "holdout_ns['ho_n'] = np.floor(holdout_ns.ho_n_prob)\n",
    "holdout_ns.loc[(holdout_ns.roll <= holdout_ns.cutoff), 'ho_n'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_ns = holdout_ns.loc[~holdout_ns['sample'].isin(rt_samples), :]\n",
    "holdout_ns = holdout_ns.loc[holdout_ns['ho_n'] > 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "heldout_ids = []\n",
    "for ix, row in holdout_ns.iterrows():\n",
    "    ind = ((dat['sample'] == row['sample'])\n",
    "           & (dat.sex_cat == row.sex_cat)\n",
    "           & (dat.age_cat == row.age_cat)\n",
    "           & (dat.race_cat == row.race_cat)\n",
    "           & (dat.hispanic_cat == row.hispanic_cat)\n",
    "           & (~dat.exclude)\n",
    "           & (~dat.participant_id.isin(rt_dat))\n",
    "           & (~dat.participant_id.isin(xp_dat.participant_id)))\n",
    "    heldout_ids.extend(dat.loc[ind, 'participant_id'].sample(n = int(row.ho_n), random_state=0).values)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mark first complete response from test-retest sample include"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get first response on each form from folks in test-retest sample without violating other exclude rules\n",
    "complete_rt_ind = (dat.participant_id.isin(rt_dat)\n",
    "                   & (dat.adult_selfreport_baseline_form_complete != 0)\n",
    "                   & (dat.parentcaregiver_baseline_form_complete != 0)\n",
    "                   & ~(dat.participant_id.isin(dif_resp_ids) & dat['sample'].isin(['Adult_US', 'Adult_US_CA', 'Adult_US_NY','Adult_London', 'Adult_Manchester', 'Adult_UK']))\n",
    "                   & ~(dat.participant_id.isin(adult_duped_ids) & ~dat.uid.isin(keep_resps))\n",
    "                   & ~(dat.uid == '5a49d6a06d85f80001c25bc4_03614'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Adult_US', 'Adult_US_RT', 'Adult_Manchester', 'Adult_UK',\n",
       "       'Adult_UK_RT', 'Parent_US_RT', 'Parent_US', 'Parent_US_CA',\n",
       "       'Parent_UK', 'Parent_UK_Manchester', 'Parent_UK_RT'], dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.loc[complete_rt_ind, 'sample'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat['date'] = pd.to_datetime(dat.timestamp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "adult_first_rts = dat.loc[complete_rt_ind & (dat.form == 'adult'),:].sort_values('date').groupby('participant_id').first().uid\n",
    "parent_first_rts = dat.loc[complete_rt_ind & (dat.form == 'parent'),:].sort_values('date').groupby('participant_id').first().uid\n",
    "first_rts = pd.concat([adult_first_rts, parent_first_rts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dat['sample_with_RT'] = dat['sample']\n",
    "dat['exclude_with_RT'] = dat['exclude']\n",
    "dat.loc[complete_rt_ind, 'exclude_with_RT'] = True\n",
    "dat.loc[dat.uid.isin(first_rts), 'exclude_with_RT'] = False\n",
    "dat.loc[dat.uid.isin(first_rts), 'sample_with_RT'] = (dat.loc[dat.uid.isin(first_rts), 'sample_with_RT']\n",
    "                                                      .str.replace('_RT',''))\n",
    "dat = dat.drop('date', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge covid data for US sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "usdat = dat.loc[dat['sample'].str.contains('US'), :].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This data is coming from Johns hopkins data\n",
    "# https://github.com/CSSEGISandData/COVID-19.git\n",
    "jhu_us_case_path = data_dir / 'time_series_covid19_confirmed_US.csv'\n",
    "jhu_us_case = pd.read_csv(jhu_us_case_path)\n",
    "\n",
    "jhu_us_deaths_path= data_dir / 'time_series_covid19_deaths_US.csv'\n",
    "jhu_us_deaths = pd.read_csv(jhu_us_deaths_path)\n",
    "\n",
    "jhu_world_case_path = data_dir / 'time_series_covid19_confirmed_global.csv'\n",
    "jhu_world_case = pd.read_csv(jhu_world_case_path)\n",
    "\n",
    "jhu_world_deaths_path = data_dir / 'time_series_covid19_deaths_global.csv'\n",
    "jhu_world_deaths = pd.read_csv(jhu_world_deaths_path)\n",
    "\n",
    "# ansi_place_path = data_dir / 'ansi_places.csv'\n",
    "# places = pd.read_csv(ansi_place_path, sep='|')\n",
    "cfix = pd.read_excel(data_dir / 'county_fixin.xlsx', sheet_name='combined').reset_index(drop=True)\n",
    "cfix = cfix.drop('Unnamed: 0', axis=1)\n",
    "cfix = cfix.loc[cfix['fixed_county'].notnull(), :]\n",
    "cfix.loc[cfix.county.notnull(),'county'] = cfix.loc[cfix.county.notnull(),'county'].astype(str)\n",
    "assert len(cfix.loc[~cfix.fixed_county.str.lower().isin(jhu_us_case.Admin2.str.lower()), :]) == 0\n",
    "sfix = pd.read_excel(data_dir / 'county_fixin.xlsx', sheet_name='state_fix')\n",
    "sfix = sfix.loc[sfix['fixed_state'].notnull(), :].drop_duplicates()\n",
    "sfix = sfix.drop('Unnamed: 0', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_state_abbrev = {\n",
    "    'Alabama': 'AL',\n",
    "    'Alaska': 'AK',\n",
    "    'American Samoa': 'AS',\n",
    "    'Arizona': 'AZ',\n",
    "    'Arkansas': 'AR',\n",
    "    'California': 'CA',\n",
    "    'Colorado': 'CO',\n",
    "    'Connecticut': 'CT',\n",
    "    'Delaware': 'DE',\n",
    "    'District of Columbia': 'DC',\n",
    "    'Florida': 'FL',\n",
    "    'Georgia': 'GA',\n",
    "    'Guam': 'GU',\n",
    "    'Hawaii': 'HI',\n",
    "    'Idaho': 'ID',\n",
    "    'Illinois': 'IL',\n",
    "    'Indiana': 'IN',\n",
    "    'Iowa': 'IA',\n",
    "    'Kansas': 'KS',\n",
    "    'Kentucky': 'KY',\n",
    "    'Louisiana': 'LA',\n",
    "    'Maine': 'ME',\n",
    "    'Maryland': 'MD',\n",
    "    'Massachusetts': 'MA',\n",
    "    'Michigan': 'MI',\n",
    "    'Minnesota': 'MN',\n",
    "    'Mississippi': 'MS',\n",
    "    'Missouri': 'MO',\n",
    "    'Montana': 'MT',\n",
    "    'Nebraska': 'NE',\n",
    "    'Nevada': 'NV',\n",
    "    'New Hampshire': 'NH',\n",
    "    'New Jersey': 'NJ',\n",
    "    'New Mexico': 'NM',\n",
    "    'New York': 'NY',\n",
    "    'North Carolina': 'NC',\n",
    "    'North Dakota': 'ND',\n",
    "    'Northern Mariana Islands':'MP',\n",
    "    'Ohio': 'OH',\n",
    "    'Oklahoma': 'OK',\n",
    "    'Oregon': 'OR',\n",
    "    'Pennsylvania': 'PA',\n",
    "    'Puerto Rico': 'PR',\n",
    "    'Rhode Island': 'RI',\n",
    "    'South Carolina': 'SC',\n",
    "    'South Dakota': 'SD',\n",
    "    'Tennessee': 'TN',\n",
    "    'Texas': 'TX',\n",
    "    'Utah': 'UT',\n",
    "    'Vermont': 'VT',\n",
    "    'Virgin Islands': 'VI',\n",
    "    'Virginia': 'VA',\n",
    "    'Washington': 'WA',\n",
    "    'West Virginia': 'WV',\n",
    "    'Wisconsin': 'WI',\n",
    "    'Wyoming': 'WY'\n",
    "}\n",
    "us_state_abbrev_inv = {v:k for k,v in us_state_abbrev.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "usdat['county'] = usdat.county.str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_drops = ['county', 'parish', 'municipio']\n",
    "for cd in county_drops:\n",
    "    usdat['county'] = usdat.county.str.replace(cd, '').str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_county_ind = ~usdat.county.str.lower().isin(jhu_us_case.Admin2.str.lower())\n",
    "long_state_ind = no_county_ind & usdat.stateetc.str.title().isin(us_state_abbrev.keys())\n",
    "abrev_ind = no_county_ind & usdat.stateetc.isin(us_state_abbrev.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "usdat['state_code'] = np.nan\n",
    "usdat.loc[abrev_ind, 'state_code'] = usdat.loc[abrev_ind, 'stateetc']\n",
    "usdat.loc[long_state_ind, 'state_code'] = usdat.loc[long_state_ind, 'stateetc'].apply(lambda x: us_state_abbrev[x.title()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "usdat['stateetc'] = usdat['stateetc'].str.strip()\n",
    "usdat['city'] = usdat['city'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usdat['county'] = usdat.county.fillna('missing value')\n",
    "# usdat['stateetc'] = usdat.stateetc.fillna('missing value')\n",
    "# usdat['city'] = usdat.city.fillna('missing value')\n",
    "\n",
    "usdat['stateetc'] = usdat.stateetc.str.lower().str.strip()\n",
    "usdat['county'] = usdat.county.str.lower().str.strip()\n",
    "usdat['city'] = usdat.city.str.lower().str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfix['county'] = cfix.county.fillna('missing value')\n",
    "# cfix['stateetc'] = cfix.stateetc.fillna('missing value')\n",
    "# cfix['city'] = cfix.city.fillna('missing value')\n",
    "cfix['stateetc'] = cfix.stateetc.str.lower().str.strip()\n",
    "cfix['county'] = cfix.county.str.lower().str.strip()\n",
    "cfix['city'] = cfix.city.str.lower().str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfix = cfix.drop_duplicates(['stateetc', 'county', 'city'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert usdat.merge(cfix, how='left', on=['stateetc', 'county', 'city'], indicator=True).shape[0] == usdat.shape[0]\n",
    "usdat = usdat.merge(cfix, how='left', on=['stateetc', 'county', 'city'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "usdat.loc[usdat.fixed_county.notnull(), 'county'] = usdat.loc[usdat.fixed_county.notnull(), 'fixed_county']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_ind = usdat.stateetc.str.upper().isin(us_state_abbrev.values())\n",
    "\n",
    "usdat.loc[code_ind, 'stateetc'] = usdat.loc[code_ind, 'stateetc'].apply(lambda x: us_state_abbrev_inv[x.upper()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "usdat['timestamp1'] = pd.to_datetime(usdat['timestamp1'] )\n",
    "sfix['timestamp1'] = pd.to_datetime(sfix.timestamp1)\n",
    "usdat['stateetc'] = usdat.stateetc.str.strip()\n",
    "usdat['stateetc'] = usdat.stateetc.str.lower().str.strip()\n",
    "usdat['county'] = usdat.county.str.lower().str.strip()\n",
    "usdat['city'] = usdat.city.str.lower().str.strip()\n",
    "sfix['stateetc'] = sfix.stateetc.str.lower().str.strip()\n",
    "sfix['county'] = sfix.county.str.lower().str.strip()\n",
    "sfix['city'] = sfix.city.str.lower().str.strip()\n",
    "sfix = sfix.drop_duplicates(['stateetc', 'county', 'city'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert usdat.merge(sfix, how='left', on=[\"participant_id\", \"timestamp1\", \"stateetc\", \"county\", \"city\"]).shape[0] == usdat.shape[0]\n",
    "usdat = usdat.merge(sfix, how='left', on=[\"participant_id\", \"timestamp1\", \"stateetc\", \"county\", \"city\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "usdat.loc[usdat.fixed_state.notnull(), 'stateetc'] = usdat.loc[usdat.fixed_state.notnull(), 'fixed_state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "usdat['date'] = usdat.timestamp1.dt.date\n",
    "usdat['stateetc'] = usdat.stateetc.str.lower().str.strip()\n",
    "usdat['county'] = usdat.county.str.lower().str.strip()\n",
    "\n",
    "assert usdat.merge(cfix, how='left', on=['stateetc', 'county', 'city'], indicator=True).shape[0] == usdat.shape[0]\n",
    "usdat = usdat.merge(cfix, how='left', on=['stateetc', 'county', 'city'])\n",
    "usdat.loc[usdat.fixed_county_y.notnull(), 'county'] = usdat.loc[usdat.fixed_county_y.notnull(), 'fixed_county_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "usdat['date'] = usdat.timestamp1.dt.date\n",
    "usdat['stateetc'] = usdat.stateetc.str.lower().str.strip()\n",
    "usdat['county'] = usdat.county.str.lower().str.strip()\n",
    "assert usdat.merge(sfix, how='left', on=['stateetc', 'county', 'city'], indicator=True).shape[0] == usdat.shape[0]\n",
    "usdat = usdat.merge(sfix, how='left', on=['stateetc', 'county', 'city'], suffixes=['', '_y'])\n",
    "usdat.loc[usdat.fixed_state_y.notnull(), 'stateetc'] = usdat.loc[usdat.fixed_state_y.notnull(), 'fixed_state_y']\n",
    "usdat['date'] = usdat.timestamp1.dt.date\n",
    "usdat['stateetc'] = usdat.stateetc.str.lower().str.strip()\n",
    "usdat['county'] = usdat.county.str.lower().str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sadly, I need to fix some cities and counties that got merged\n",
    "cc_fix = pd.read_csv(data_dir / 'county_cities.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_fix['fixed_county'] = cc_fix.fixed_county.str.lower()\n",
    "cc_fix['fixed_county'] = cc_fix.fixed_county.str.replace(\"county\", \"\").str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for ix,row in cc_fix.iterrows():\n",
    "    usdat.loc[usdat.uid == row.uid, 'county'] = row.fixed_county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "jhu_us_case['Province_State'] = jhu_us_case.Province_State.str.lower()\n",
    "jhu_us_case['Admin2'] = jhu_us_case.Admin2.str.lower()\n",
    "jhu_us_case.loc[jhu_us_case.FIPS.notnull(), 'FIPS'] = jhu_us_case.loc[jhu_us_case.FIPS.notnull(), 'FIPS'].apply(lambda x: f'{int(x):05d}')\n",
    "jhu_us_case.loc[jhu_us_case.FIPS.notnull(), 'stateFIPS'] = jhu_us_case.loc[jhu_us_case.FIPS.notnull(), 'FIPS'].str[:2]\n",
    "\n",
    "jhu_us_deaths['Province_State'] = jhu_us_deaths.Province_State.str.lower()\n",
    "jhu_us_deaths['Admin2'] = jhu_us_deaths.Admin2.str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_cols = jhu_us_case.columns[jhu_us_case.columns.str.contains('/20')]\n",
    "meta_cols = jhu_us_case.columns[~jhu_us_case.columns.str.contains('/20')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "jhu_us_new_case = jhu_us_case.copy()\n",
    "jhu_us_new_case.loc[:, list(date_cols[1:])] = jhu_us_case.loc[:, date_cols[1:]].values - jhu_us_case.loc[:, date_cols[:-1]].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "jhu_us_new_deaths = jhu_us_deaths.copy()\n",
    "jhu_us_new_deaths.loc[:, list(date_cols[1:])] = jhu_us_deaths.loc[:, date_cols[1:]].values - jhu_us_deaths.loc[:, date_cols[:-1]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "jhu_us_state_case = jhu_us_case.groupby(['Province_State']).sum().reset_index()\n",
    "jhu_us_state_new_case = jhu_us_new_case.groupby(['Province_State']).sum().reset_index()\n",
    "jhu_us_state_deaths = jhu_us_deaths.groupby(['Province_State']).sum().reset_index()\n",
    "jhu_us_state_new_deaths = jhu_us_new_deaths.groupby(['Province_State']).sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "jhu_world_new_case = jhu_world_case.copy()\n",
    "jhu_world_new_case.loc[:, list(date_cols[1:])] = jhu_world_case.loc[:, date_cols[1:]].values - jhu_world_case.loc[:, date_cols[:-1]].values\n",
    "jhu_world_new_deaths = jhu_world_deaths.copy()\n",
    "jhu_world_new_deaths.loc[:, list(date_cols[1:])] = jhu_world_deaths.loc[:, date_cols[1:]].values - jhu_world_deaths.loc[:, date_cols[:-1]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dat = []\n",
    "bad_rows = []\n",
    "for ix, row in usdat.iterrows():\n",
    "    dt_str = f'{row.timestamp1.date().month}/{row.timestamp1.date().day}/{row.timestamp1.date().year%2000}'\n",
    "    ind = ((jhu_us_case.Province_State == row.stateetc)\n",
    "       & (jhu_us_case.Admin2 == row.county))\n",
    "    if ind.sum() > 0:\n",
    "        row['FIPS'] = jhu_us_case.loc[ind, 'FIPS'].values[0]\n",
    "        row['total_local_cases'] = jhu_us_case.loc[ind, dt_str].values[0]\n",
    "        row['new_local_cases'] = jhu_us_new_case.loc[ind, dt_str].values[0]\n",
    "\n",
    "    ind = jhu_us_state_case.Province_State == row.stateetc\n",
    "    if ind.sum() > 0:\n",
    "        row['total_stateetc_cases'] = jhu_us_state_case.loc[ind, dt_str].values[0]\n",
    "        row['new_stateetc_cases'] = jhu_us_state_new_case.loc[ind, dt_str].values[0]\n",
    "        \n",
    "    ind = ((jhu_world_case['Province/State'].isnull())\n",
    "           & (jhu_world_case['Country/Region'] == row.country_name))\n",
    "    if ind.sum() > 0:\n",
    "        row['total_country_cases'] = jhu_world_case.loc[ind, dt_str].values[0]\n",
    "        row['new_country_cases'] = jhu_world_new_case.loc[ind, dt_str].values[0]\n",
    "\n",
    "    ind = ((jhu_us_deaths.Province_State == row.stateetc)\n",
    "           & (jhu_us_deaths.Admin2 == row.county))\n",
    "    if ind.sum() > 0:\n",
    "        row['total_local_deaths'] = jhu_us_deaths.loc[ind, dt_str].values[0]\n",
    "        row['new_local_deaths'] = jhu_us_new_deaths.loc[ind, dt_str].values[0]\n",
    "\n",
    "    ind = jhu_us_state_deaths.Province_State == row.stateetc\n",
    "    if ind.sum() > 0:\n",
    "        row['total_stateetc_deaths'] = jhu_us_state_deaths.loc[ind, dt_str].values[0]\n",
    "        row['new_stateetc_deaths'] = jhu_us_state_new_deaths.loc[ind, dt_str].values[0]\n",
    "        \n",
    "    ind = ((jhu_world_deaths['Province/State'].isnull())\n",
    "           & (jhu_world_deaths['Country/Region'] == row.country_name))\n",
    "    if ind.sum() > 0:\n",
    "        row['total_country_deaths'] = jhu_world_deaths.loc[ind, dt_str].values[0]\n",
    "        row['new_country_deaths'] = jhu_world_new_deaths.loc[ind, dt_str].values[0]\n",
    "    merged_dat.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cols = ['total_local_cases', 'total_stateetc_cases', 'total_country_cases',\n",
    "              'total_local_deaths', 'total_stateetc_deaths', 'total_country_deaths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.DataFrame(merged_dat)\n",
    "merged_df = merged_df.drop(['state_code','fixed_county_x','fixed_county_2_x','fixed_county_3_x','fixed_state','date','fixed_county_y','fixed_county_2_y','fixed_county_3_y','participant_id_y','timestamp1_y','fixed_state_y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    }
   ],
   "source": [
    "missing_geo_ind = merged_df.loc[:, total_cols].isnull().sum(1) > 0\n",
    "assert missing_geo_ind.sum() == 37\n",
    "print(missing_geo_ind.sum())\n",
    "# Uncomment this line to investigate further if the above assert fails\n",
    "#merged_df.loc[missing_geo_ind,  ['timestamp1', 'country_name', 'stateetc', 'county', 'city'] +total_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the city/county thing really is all straigtened out\n",
    "for ix,row in cc_fix.iterrows():\n",
    "    assert (merged_df.loc[merged_df.uid == row.uid, 'FIPS'] == str(row.fixed_FIPS)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.loc[missing_geo_ind, 'exclude'] = True\n",
    "dat.loc[dat.uid.isin(merged_df.loc[missing_geo_ind, 'uid']), 'exclude'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Johns hopkins has negative new cases\n",
    "# This link: https://github.com/CSSEGISandData/COVID-19/issues/2291 directs us to\n",
    "# USA facts: https://usafacts.org/visualizations/coronavirus-covid-19-spread-map/\n",
    "# Going to merge in their data by FIPS for US cases\n",
    "# Also has massive NYC weirdness: https://github.com/CSSEGISandData/COVID-19/issues/2212\n",
    "usf_us_case = pd.read_csv(data_dir / 'covid_confirmed_usafacts.csv')\n",
    "usf_date_cols = list(usf_us_case.columns[usf_us_case.columns.str.contains('/20')].values)\n",
    "usf_us_case['FIPS'] = usf_us_case.countyFIPS.apply(lambda x: f'{x:05d}')\n",
    "usf_us_case['stateFIPS'] = usf_us_case.stateFIPS.apply(lambda x: f'{x:02d}')\n",
    "usf_us_new_case = usf_us_case.copy()\n",
    "usf_us_new_case.loc[:, list(date_cols[1:])] = usf_us_case.loc[:, date_cols[1:]].values - usf_us_case.loc[:, date_cols[:-1]].values\n",
    "\n",
    "usf_us_state_case = usf_us_case.groupby(\"State\")[usf_date_cols].sum().reset_index()\n",
    "usf_us_state_new_case = usf_us_new_case.groupby(\"State\")[usf_date_cols].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "usf_us_deaths = pd.read_csv(data_dir / 'covid_deaths_usafacts.csv')\n",
    "usf_date_cols = list(usf_us_deaths.columns[usf_us_deaths.columns.str.contains('/20')].values)\n",
    "usf_us_deaths['FIPS'] = usf_us_deaths.countyFIPS.apply(lambda x: f'{x:05d}')\n",
    "usf_us_deaths['stateFIPS'] = usf_us_deaths.stateFIPS.apply(lambda x: f'{x:02d}')\n",
    "usf_us_new_deaths = usf_us_deaths.copy()\n",
    "usf_us_new_deaths.loc[:, list(date_cols[1:])] = usf_us_deaths.loc[:, date_cols[1:]].values - usf_us_deaths.loc[:, date_cols[:-1]].values\n",
    "\n",
    "usf_us_state_deaths = usf_us_deaths.groupby(\"State\")[usf_date_cols].sum().reset_index()\n",
    "usf_us_state_new_deaths = usf_us_new_deaths.groupby(\"State\")[usf_date_cols].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['date'] = pd.to_datetime(merged_df.timestamp1).apply(lambda x: f'{x.date().month}/{x.date().day}/{x.date().year%2000}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_long(df, name, index='FIPS'):\n",
    "    result = (df.loc[df[index] != '00000', [index] + usf_date_cols]\n",
    "                    .set_index(index)\n",
    "                    .stack()\n",
    "                    .reset_index()\n",
    "                    .rename(columns={'level_1': 'date', 0: name}))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "usf_us_case_long = make_long(usf_us_case, 'total_local_cases')\n",
    "usf_us_new_case_long = make_long(usf_us_new_case, 'new_local_cases')\n",
    "usf_us_deaths_long = make_long(usf_us_deaths, 'total_local_deaths')\n",
    "usf_us_new_deaths_long = make_long(usf_us_new_deaths, 'new_local_deaths')\n",
    "usf_us_case_long = usf_us_case_long.merge(usf_us_new_case_long, how='left', on=['FIPS', 'date'])\n",
    "usf_us_case_long = usf_us_case_long.merge(usf_us_deaths_long, how='left', on=['FIPS', 'date'])\n",
    "usf_us_case_long = usf_us_case_long.merge(usf_us_new_deaths_long, how='left', on=['FIPS', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "usf_us_state_case_long = make_long(usf_us_state_case, 'total_stateetc_cases', 'State')\n",
    "usf_us_state_new_case_long = make_long(usf_us_state_new_case, 'new_stateetc_cases', 'State')\n",
    "usf_us_state_deaths_long = make_long(usf_us_state_deaths, 'total_stateetc_deaths', 'State')\n",
    "usf_us_state_new_deaths_long = make_long(usf_us_state_new_deaths, 'new_stateetc_deaths', 'State')\n",
    "usf_us_state_case_long = usf_us_state_case_long.merge(usf_us_state_new_case_long, how='left', on=['State', 'date'])\n",
    "usf_us_state_case_long = usf_us_state_case_long.merge(usf_us_state_deaths_long, how='left', on=['State', 'date'])\n",
    "usf_us_state_case_long = usf_us_state_case_long.merge(usf_us_state_new_deaths_long, how='left', on=['State', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "usf_us_state_case_long['stateetc'] = usf_us_state_case_long.State.apply(lambda x: us_state_abbrev_inv[x]).str.lower()\n",
    "usf_us_state_case_long = usf_us_state_case_long.drop('State', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.merge(usf_us_case_long, on=['FIPS', 'date'], how='left',suffixes=['','_usf'])\n",
    "merged_df = merged_df.merge(usf_us_state_case_long, on=['stateetc', 'date'], how='left',suffixes=['','_usf'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge in us population estimates and calculate population normlazied estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "uspop = pd.read_csv(data_dir / 'co-est2019-alldata.csv')\n",
    "uspop['STATE'] = uspop['STATE'].apply(lambda x: f'{int(x):02d}')\n",
    "uspop['COUNTY'] = uspop['COUNTY'].apply(lambda x: f'{int(x):03d}')\n",
    "uspop['FIPS'] = uspop.STATE + uspop.COUNTY\n",
    "uspop = uspop.rename(columns={\"POPESTIMATE2019\": \"population\"})\n",
    "usctypop = uspop.loc[uspop.COUNTY != '000', :].copy()\n",
    "usstpop = uspop.loc[uspop.COUNTY == '000', :].copy()\n",
    "usstpop = usstpop.rename(columns={'STATE':'stateFIPS'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "usstpop['stateetc'] = usstpop['STNAME'].str.lower().str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "stFIPS_lut = usstpop.loc[:, ['stateetc', 'stateFIPS']]\n",
    "assert stFIPS_lut.stateetc.duplicated().sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.merge(stFIPS_lut, how='left', on='stateetc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge city/county with same name\n",
    "merged_df = merged_df.merge(usctypop.loc[:, ['FIPS', 'population']], on='FIPS', how='left')\n",
    "\n",
    "merged_df = merged_df.merge(usstpop.loc[:, ['stateFIPS', 'population']], on='stateFIPS', suffixes = ['', '_stateetc'], how='left')\n",
    "\n",
    "merged_df['total_local_deaths_per_case'] = merged_df.total_local_deaths / merged_df.total_local_cases\n",
    "merged_df['total_local_deaths_per_10000'] = (merged_df.total_local_deaths / merged_df.population) * 10000\n",
    "merged_df['total_local_cases_per_10000'] = (merged_df.total_local_cases / merged_df.population) * 10000\n",
    "merged_df['new_local_deaths_per_case'] = merged_df.new_local_deaths / merged_df.total_local_cases\n",
    "merged_df['new_local_deaths_per_10000'] = (merged_df.new_local_deaths / merged_df.population) * 10000\n",
    "merged_df['new_local_cases_per_10000'] = (merged_df.new_local_cases / merged_df.population) * 10000\n",
    "merged_df['total_stateetc_deaths_per_case'] = merged_df.total_stateetc_deaths / merged_df.total_stateetc_cases\n",
    "merged_df['total_stateetc_deaths_per_10000'] = (merged_df.total_stateetc_deaths / merged_df.population) * 10000\n",
    "merged_df['total_stateetc_cases_per_10000'] = (merged_df.total_stateetc_cases / merged_df.population) * 10000\n",
    "merged_df['new_stateetc_deaths_per_case'] = merged_df.new_stateetc_deaths / merged_df.total_stateetc_cases\n",
    "merged_df['new_stateetc_deaths_per_10000'] = (merged_df.new_stateetc_deaths / merged_df.population_stateetc) * 10000\n",
    "merged_df['new_stateetc_cases_per_10000'] = (merged_df.new_stateetc_cases / merged_df.population_stateetc) * 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['total_local_deaths_per_case_usf'] = merged_df.total_local_deaths_usf / merged_df.total_local_cases_usf\n",
    "merged_df['total_local_deaths_per_10000_usf'] = (merged_df.total_local_deaths_usf / merged_df.population) * 10000\n",
    "merged_df['total_local_cases_per_10000_usf'] = (merged_df.total_local_cases_usf / merged_df.population) * 10000\n",
    "merged_df['new_local_deaths_per_case_usf'] = merged_df.new_local_deaths_usf / merged_df.total_local_cases_usf\n",
    "merged_df['new_local_deaths_per_10000_usf'] = (merged_df.new_local_deaths_usf / merged_df.population) * 10000\n",
    "merged_df['new_local_cases_per_10000_usf'] = (merged_df.new_local_cases_usf / merged_df.population) * 10000\n",
    "merged_df['total_stateetc_deaths_per_case_usf'] = merged_df.total_stateetc_deaths_usf / merged_df.total_stateetc_cases_usf\n",
    "merged_df['total_stateetc_deaths_per_10000_usf'] = (merged_df.total_stateetc_deaths_usf / merged_df.population) * 10000\n",
    "merged_df['total_stateetc_cases_per_10000_usf'] = (merged_df.total_stateetc_cases_usf / merged_df.population) * 10000\n",
    "merged_df['new_stateetc_deaths_per_case_usf'] = merged_df.new_stateetc_deaths_usf / merged_df.total_stateetc_cases_usf\n",
    "merged_df['new_stateetc_deaths_per_10000_usf'] = (merged_df.new_stateetc_deaths_usf / merged_df.population_stateetc) * 10000\n",
    "merged_df['new_stateetc_cases_per_10000_usf'] = (merged_df.new_stateetc_cases_usf / merged_df.population_stateetc) * 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define epicenters and get distance to epicenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "jhu_us_case = jhu_us_case.merge(uspop.loc[:,['FIPS', 'population']], how='left', on='FIPS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2020-04-17 23:09:00'), Timestamp('2020-04-07 10:29:00'))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.timestamp1.max(), merged_df.timestamp1.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "jhu_us_prev = jhu_us_case.copy()\n",
    "jhu_us_prev = jhu_us_prev.loc[jhu_us_prev.Admin2.notnull() & jhu_us_prev.population.notnull(), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "epis = []\n",
    "for dc in date_cols:\n",
    "    prev =  jhu_us_prev.loc[:, dc]/jhu_us_prev.population * 10000\n",
    "    epi_ind = (prev > prev.quantile(0.999)) & (jhu_us_prev.loc[:, dc] > jhu_us_prev.loc[:, dc].quantile(0.999))\n",
    "    tmp = jhu_us_prev.loc[epi_ind, ['FIPS', 'Admin2', 'Province_State', dc]]\n",
    "    tmp = tmp.rename(columns={dc:'count'})\n",
    "    tmp['date'] = dc\n",
    "    tmp['prev'] = prev[epi_ind]\n",
    "    epis.append(tmp)\n",
    "epis= pd.concat(epis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "usf_us_case = usf_us_case.merge(uspop.loc[:,['FIPS', 'population']], how='left', on='FIPS')\n",
    "usf_us_prev = usf_us_case.copy()\n",
    "usf_us_prev = usf_us_prev.loc[usf_us_prev.countyFIPS != 0 & usf_us_prev.population.notnull(), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "epis = []\n",
    "for dc in date_cols:\n",
    "    prev =  usf_us_prev.loc[:, dc]/usf_us_prev.population * 10000\n",
    "    epi_ind = (prev > prev.quantile(0.999)) & (usf_us_prev.loc[:, dc] > usf_us_prev.loc[:, dc].quantile(0.999))\n",
    "    tmp = usf_us_prev.loc[epi_ind, ['FIPS', 'County Name', 'State', dc]]\n",
    "    tmp = tmp.rename(columns={dc:'count'})\n",
    "    tmp['date'] = dc\n",
    "    tmp['prev'] = prev[epi_ind]\n",
    "    epis.append(tmp)\n",
    "epis= pd.concat(epis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS</th>\n",
       "      <th>County Name</th>\n",
       "      <th>State</th>\n",
       "      <th>count</th>\n",
       "      <th>date</th>\n",
       "      <th>prev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3019</th>\n",
       "      <td>53033</td>\n",
       "      <td>King County</td>\n",
       "      <td>WA</td>\n",
       "      <td>1</td>\n",
       "      <td>1/22/20</td>\n",
       "      <td>0.004439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3019</th>\n",
       "      <td>53033</td>\n",
       "      <td>King County</td>\n",
       "      <td>WA</td>\n",
       "      <td>1</td>\n",
       "      <td>1/23/20</td>\n",
       "      <td>0.004439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>17031</td>\n",
       "      <td>Cook County</td>\n",
       "      <td>IL</td>\n",
       "      <td>1</td>\n",
       "      <td>1/24/20</td>\n",
       "      <td>0.001942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3019</th>\n",
       "      <td>53033</td>\n",
       "      <td>King County</td>\n",
       "      <td>WA</td>\n",
       "      <td>1</td>\n",
       "      <td>1/24/20</td>\n",
       "      <td>0.004439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>17031</td>\n",
       "      <td>Cook County</td>\n",
       "      <td>IL</td>\n",
       "      <td>1</td>\n",
       "      <td>1/25/20</td>\n",
       "      <td>0.001942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3019</th>\n",
       "      <td>53033</td>\n",
       "      <td>King County</td>\n",
       "      <td>WA</td>\n",
       "      <td>1</td>\n",
       "      <td>1/25/20</td>\n",
       "      <td>0.004439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>05125</td>\n",
       "      <td>Saline County</td>\n",
       "      <td>AR</td>\n",
       "      <td>4</td>\n",
       "      <td>1/27/20</td>\n",
       "      <td>0.326699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>06085</td>\n",
       "      <td>Santa Clara County</td>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "      <td>1/29/20</td>\n",
       "      <td>0.010374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>06085</td>\n",
       "      <td>Santa Clara County</td>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "      <td>1/30/20</td>\n",
       "      <td>0.010374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>06085</td>\n",
       "      <td>Santa Clara County</td>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "      <td>1/31/20</td>\n",
       "      <td>0.010374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>17031</td>\n",
       "      <td>Cook County</td>\n",
       "      <td>IL</td>\n",
       "      <td>2</td>\n",
       "      <td>1/31/20</td>\n",
       "      <td>0.003883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>06085</td>\n",
       "      <td>Santa Clara County</td>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "      <td>2/1/20</td>\n",
       "      <td>0.010374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>17031</td>\n",
       "      <td>Cook County</td>\n",
       "      <td>IL</td>\n",
       "      <td>2</td>\n",
       "      <td>2/1/20</td>\n",
       "      <td>0.003883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>06085</td>\n",
       "      <td>Santa Clara County</td>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "      <td>2/2/20</td>\n",
       "      <td>0.010374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>17031</td>\n",
       "      <td>Cook County</td>\n",
       "      <td>IL</td>\n",
       "      <td>2</td>\n",
       "      <td>2/2/20</td>\n",
       "      <td>0.003883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>06069</td>\n",
       "      <td>San Benito County</td>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "      <td>2/3/20</td>\n",
       "      <td>0.318431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>06085</td>\n",
       "      <td>Santa Clara County</td>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "      <td>2/3/20</td>\n",
       "      <td>0.010374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>06069</td>\n",
       "      <td>San Benito County</td>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "      <td>2/4/20</td>\n",
       "      <td>0.318431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>06085</td>\n",
       "      <td>Santa Clara County</td>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "      <td>2/4/20</td>\n",
       "      <td>0.010374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>06069</td>\n",
       "      <td>San Benito County</td>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "      <td>2/5/20</td>\n",
       "      <td>0.318431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>06085</td>\n",
       "      <td>Santa Clara County</td>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "      <td>2/5/20</td>\n",
       "      <td>0.010374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>06069</td>\n",
       "      <td>San Benito County</td>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "      <td>2/6/20</td>\n",
       "      <td>0.318431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>06085</td>\n",
       "      <td>Santa Clara County</td>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "      <td>2/6/20</td>\n",
       "      <td>0.010374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>06069</td>\n",
       "      <td>San Benito County</td>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "      <td>2/7/20</td>\n",
       "      <td>0.318431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>06085</td>\n",
       "      <td>Santa Clara County</td>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "      <td>2/7/20</td>\n",
       "      <td>0.010374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>06069</td>\n",
       "      <td>San Benito County</td>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "      <td>2/8/20</td>\n",
       "      <td>0.318431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>06085</td>\n",
       "      <td>Santa Clara County</td>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "      <td>2/8/20</td>\n",
       "      <td>0.010374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>06069</td>\n",
       "      <td>San Benito County</td>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "      <td>2/9/20</td>\n",
       "      <td>0.318431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>06085</td>\n",
       "      <td>Santa Clara County</td>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "      <td>2/9/20</td>\n",
       "      <td>0.010374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>06069</td>\n",
       "      <td>San Benito County</td>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "      <td>2/10/20</td>\n",
       "      <td>0.318431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>06085</td>\n",
       "      <td>Santa Clara County</td>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "      <td>2/10/20</td>\n",
       "      <td>0.010374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>06069</td>\n",
       "      <td>San Benito County</td>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "      <td>2/11/20</td>\n",
       "      <td>0.318431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>06085</td>\n",
       "      <td>Santa Clara County</td>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "      <td>2/11/20</td>\n",
       "      <td>0.010374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>06069</td>\n",
       "      <td>San Benito County</td>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "      <td>2/12/20</td>\n",
       "      <td>0.318431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>06085</td>\n",
       "      <td>Santa Clara County</td>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "      <td>2/12/20</td>\n",
       "      <td>0.010374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>06069</td>\n",
       "      <td>San Benito County</td>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "      <td>2/13/20</td>\n",
       "      <td>0.318431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>06073</td>\n",
       "      <td>San Diego County</td>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "      <td>2/13/20</td>\n",
       "      <td>0.005991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>06085</td>\n",
       "      <td>Santa Clara County</td>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "      <td>2/13/20</td>\n",
       "      <td>0.010374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>06069</td>\n",
       "      <td>San Benito County</td>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "      <td>2/14/20</td>\n",
       "      <td>0.318431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>06073</td>\n",
       "      <td>San Diego County</td>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "      <td>2/14/20</td>\n",
       "      <td>0.005991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>06085</td>\n",
       "      <td>Santa Clara County</td>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "      <td>2/14/20</td>\n",
       "      <td>0.010374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>06069</td>\n",
       "      <td>San Benito County</td>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "      <td>2/15/20</td>\n",
       "      <td>0.318431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>06073</td>\n",
       "      <td>San Diego County</td>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "      <td>2/15/20</td>\n",
       "      <td>0.005991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>06085</td>\n",
       "      <td>Santa Clara County</td>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "      <td>2/15/20</td>\n",
       "      <td>0.010374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>06069</td>\n",
       "      <td>San Benito County</td>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "      <td>2/16/20</td>\n",
       "      <td>0.318431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>06073</td>\n",
       "      <td>San Diego County</td>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "      <td>2/16/20</td>\n",
       "      <td>0.005991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>06085</td>\n",
       "      <td>Santa Clara County</td>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "      <td>2/16/20</td>\n",
       "      <td>0.010374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>06069</td>\n",
       "      <td>San Benito County</td>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "      <td>2/17/20</td>\n",
       "      <td>0.318431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>06073</td>\n",
       "      <td>San Diego County</td>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "      <td>2/17/20</td>\n",
       "      <td>0.005991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>06085</td>\n",
       "      <td>Santa Clara County</td>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "      <td>2/17/20</td>\n",
       "      <td>0.010374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>06069</td>\n",
       "      <td>San Benito County</td>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "      <td>2/18/20</td>\n",
       "      <td>0.318431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>06073</td>\n",
       "      <td>San Diego County</td>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "      <td>2/18/20</td>\n",
       "      <td>0.005991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>06085</td>\n",
       "      <td>Santa Clara County</td>\n",
       "      <td>CA</td>\n",
       "      <td>3</td>\n",
       "      <td>2/18/20</td>\n",
       "      <td>0.015561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>06069</td>\n",
       "      <td>San Benito County</td>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "      <td>2/19/20</td>\n",
       "      <td>0.318431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>06073</td>\n",
       "      <td>San Diego County</td>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "      <td>2/19/20</td>\n",
       "      <td>0.005991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>06085</td>\n",
       "      <td>Santa Clara County</td>\n",
       "      <td>CA</td>\n",
       "      <td>3</td>\n",
       "      <td>2/19/20</td>\n",
       "      <td>0.015561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>06069</td>\n",
       "      <td>San Benito County</td>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "      <td>2/20/20</td>\n",
       "      <td>0.318431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>06073</td>\n",
       "      <td>San Diego County</td>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "      <td>2/20/20</td>\n",
       "      <td>0.005991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>06085</td>\n",
       "      <td>Santa Clara County</td>\n",
       "      <td>CA</td>\n",
       "      <td>3</td>\n",
       "      <td>2/20/20</td>\n",
       "      <td>0.015561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>06069</td>\n",
       "      <td>San Benito County</td>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "      <td>2/21/20</td>\n",
       "      <td>0.318431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>06085</td>\n",
       "      <td>Santa Clara County</td>\n",
       "      <td>CA</td>\n",
       "      <td>4</td>\n",
       "      <td>2/21/20</td>\n",
       "      <td>0.020748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>06069</td>\n",
       "      <td>San Benito County</td>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "      <td>2/22/20</td>\n",
       "      <td>0.318431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>06085</td>\n",
       "      <td>Santa Clara County</td>\n",
       "      <td>CA</td>\n",
       "      <td>4</td>\n",
       "      <td>2/22/20</td>\n",
       "      <td>0.020748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>06069</td>\n",
       "      <td>San Benito County</td>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "      <td>2/23/20</td>\n",
       "      <td>0.318431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>06085</td>\n",
       "      <td>Santa Clara County</td>\n",
       "      <td>CA</td>\n",
       "      <td>4</td>\n",
       "      <td>2/23/20</td>\n",
       "      <td>0.020748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>06069</td>\n",
       "      <td>San Benito County</td>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "      <td>2/24/20</td>\n",
       "      <td>0.318431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>06085</td>\n",
       "      <td>Santa Clara County</td>\n",
       "      <td>CA</td>\n",
       "      <td>5</td>\n",
       "      <td>2/24/20</td>\n",
       "      <td>0.025936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>06069</td>\n",
       "      <td>San Benito County</td>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "      <td>2/25/20</td>\n",
       "      <td>0.318431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>06085</td>\n",
       "      <td>Santa Clara County</td>\n",
       "      <td>CA</td>\n",
       "      <td>5</td>\n",
       "      <td>2/25/20</td>\n",
       "      <td>0.025936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>06069</td>\n",
       "      <td>San Benito County</td>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "      <td>2/26/20</td>\n",
       "      <td>0.318431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>06085</td>\n",
       "      <td>Santa Clara County</td>\n",
       "      <td>CA</td>\n",
       "      <td>7</td>\n",
       "      <td>2/26/20</td>\n",
       "      <td>0.036310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>06085</td>\n",
       "      <td>Santa Clara County</td>\n",
       "      <td>CA</td>\n",
       "      <td>7</td>\n",
       "      <td>2/27/20</td>\n",
       "      <td>0.036310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>06085</td>\n",
       "      <td>Santa Clara County</td>\n",
       "      <td>CA</td>\n",
       "      <td>9</td>\n",
       "      <td>2/28/20</td>\n",
       "      <td>0.046684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>06085</td>\n",
       "      <td>Santa Clara County</td>\n",
       "      <td>CA</td>\n",
       "      <td>13</td>\n",
       "      <td>2/29/20</td>\n",
       "      <td>0.067433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3019</th>\n",
       "      <td>53033</td>\n",
       "      <td>King County</td>\n",
       "      <td>WA</td>\n",
       "      <td>6</td>\n",
       "      <td>2/29/20</td>\n",
       "      <td>0.026634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>06085</td>\n",
       "      <td>Santa Clara County</td>\n",
       "      <td>CA</td>\n",
       "      <td>13</td>\n",
       "      <td>3/1/20</td>\n",
       "      <td>0.067433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3019</th>\n",
       "      <td>53033</td>\n",
       "      <td>King County</td>\n",
       "      <td>WA</td>\n",
       "      <td>9</td>\n",
       "      <td>3/1/20</td>\n",
       "      <td>0.039951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>06085</td>\n",
       "      <td>Santa Clara County</td>\n",
       "      <td>CA</td>\n",
       "      <td>18</td>\n",
       "      <td>3/2/20</td>\n",
       "      <td>0.093368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>06085</td>\n",
       "      <td>Santa Clara County</td>\n",
       "      <td>CA</td>\n",
       "      <td>20</td>\n",
       "      <td>3/3/20</td>\n",
       "      <td>0.103742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3019</th>\n",
       "      <td>53033</td>\n",
       "      <td>King County</td>\n",
       "      <td>WA</td>\n",
       "      <td>31</td>\n",
       "      <td>3/4/20</td>\n",
       "      <td>0.137608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3019</th>\n",
       "      <td>53033</td>\n",
       "      <td>King County</td>\n",
       "      <td>WA</td>\n",
       "      <td>51</td>\n",
       "      <td>3/5/20</td>\n",
       "      <td>0.226387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3033</th>\n",
       "      <td>53061</td>\n",
       "      <td>Snohomish County</td>\n",
       "      <td>WA</td>\n",
       "      <td>18</td>\n",
       "      <td>3/5/20</td>\n",
       "      <td>0.218956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3019</th>\n",
       "      <td>53033</td>\n",
       "      <td>King County</td>\n",
       "      <td>WA</td>\n",
       "      <td>58</td>\n",
       "      <td>3/6/20</td>\n",
       "      <td>0.257459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922</th>\n",
       "      <td>36119</td>\n",
       "      <td>Westchester County</td>\n",
       "      <td>NY</td>\n",
       "      <td>57</td>\n",
       "      <td>3/7/20</td>\n",
       "      <td>0.589144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3033</th>\n",
       "      <td>53061</td>\n",
       "      <td>Snohomish County</td>\n",
       "      <td>WA</td>\n",
       "      <td>27</td>\n",
       "      <td>3/7/20</td>\n",
       "      <td>0.328434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922</th>\n",
       "      <td>36119</td>\n",
       "      <td>Westchester County</td>\n",
       "      <td>NY</td>\n",
       "      <td>83</td>\n",
       "      <td>3/8/20</td>\n",
       "      <td>0.857876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3019</th>\n",
       "      <td>53033</td>\n",
       "      <td>King County</td>\n",
       "      <td>WA</td>\n",
       "      <td>83</td>\n",
       "      <td>3/8/20</td>\n",
       "      <td>0.368433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3033</th>\n",
       "      <td>53061</td>\n",
       "      <td>Snohomish County</td>\n",
       "      <td>WA</td>\n",
       "      <td>31</td>\n",
       "      <td>3/8/20</td>\n",
       "      <td>0.377091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922</th>\n",
       "      <td>36119</td>\n",
       "      <td>Westchester County</td>\n",
       "      <td>NY</td>\n",
       "      <td>98</td>\n",
       "      <td>3/9/20</td>\n",
       "      <td>1.012914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922</th>\n",
       "      <td>36119</td>\n",
       "      <td>Westchester County</td>\n",
       "      <td>NY</td>\n",
       "      <td>108</td>\n",
       "      <td>3/10/20</td>\n",
       "      <td>1.116272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922</th>\n",
       "      <td>36119</td>\n",
       "      <td>Westchester County</td>\n",
       "      <td>NY</td>\n",
       "      <td>121</td>\n",
       "      <td>3/11/20</td>\n",
       "      <td>1.250638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922</th>\n",
       "      <td>36119</td>\n",
       "      <td>Westchester County</td>\n",
       "      <td>NY</td>\n",
       "      <td>380</td>\n",
       "      <td>3/17/20</td>\n",
       "      <td>3.927624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922</th>\n",
       "      <td>36119</td>\n",
       "      <td>Westchester County</td>\n",
       "      <td>NY</td>\n",
       "      <td>538</td>\n",
       "      <td>3/18/20</td>\n",
       "      <td>5.560689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922</th>\n",
       "      <td>36119</td>\n",
       "      <td>Westchester County</td>\n",
       "      <td>NY</td>\n",
       "      <td>798</td>\n",
       "      <td>3/19/20</td>\n",
       "      <td>8.248011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922</th>\n",
       "      <td>36119</td>\n",
       "      <td>Westchester County</td>\n",
       "      <td>NY</td>\n",
       "      <td>1091</td>\n",
       "      <td>3/20/20</td>\n",
       "      <td>11.276416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1893</th>\n",
       "      <td>36061</td>\n",
       "      <td>New York County</td>\n",
       "      <td>NY</td>\n",
       "      <td>1863</td>\n",
       "      <td>3/21/20</td>\n",
       "      <td>11.438529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922</th>\n",
       "      <td>36119</td>\n",
       "      <td>Westchester County</td>\n",
       "      <td>NY</td>\n",
       "      <td>1385</td>\n",
       "      <td>3/21/20</td>\n",
       "      <td>14.315157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1892</th>\n",
       "      <td>36059</td>\n",
       "      <td>Nassau County</td>\n",
       "      <td>NY</td>\n",
       "      <td>1900</td>\n",
       "      <td>3/22/20</td>\n",
       "      <td>14.002258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922</th>\n",
       "      <td>36119</td>\n",
       "      <td>Westchester County</td>\n",
       "      <td>NY</td>\n",
       "      <td>2894</td>\n",
       "      <td>3/23/20</td>\n",
       "      <td>29.911959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922</th>\n",
       "      <td>36119</td>\n",
       "      <td>Westchester County</td>\n",
       "      <td>NY</td>\n",
       "      <td>3891</td>\n",
       "      <td>3/24/20</td>\n",
       "      <td>40.216805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1903</th>\n",
       "      <td>36081</td>\n",
       "      <td>Queens County</td>\n",
       "      <td>NY</td>\n",
       "      <td>6420</td>\n",
       "      <td>3/25/20</td>\n",
       "      <td>28.484492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922</th>\n",
       "      <td>36119</td>\n",
       "      <td>Westchester County</td>\n",
       "      <td>NY</td>\n",
       "      <td>4691</td>\n",
       "      <td>3/25/20</td>\n",
       "      <td>48.485487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1903</th>\n",
       "      <td>36081</td>\n",
       "      <td>Queens County</td>\n",
       "      <td>NY</td>\n",
       "      <td>7362</td>\n",
       "      <td>3/26/20</td>\n",
       "      <td>32.663992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922</th>\n",
       "      <td>36119</td>\n",
       "      <td>Westchester County</td>\n",
       "      <td>NY</td>\n",
       "      <td>5944</td>\n",
       "      <td>3/26/20</td>\n",
       "      <td>61.436312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922</th>\n",
       "      <td>36119</td>\n",
       "      <td>Westchester County</td>\n",
       "      <td>NY</td>\n",
       "      <td>7187</td>\n",
       "      <td>3/27/20</td>\n",
       "      <td>74.283777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922</th>\n",
       "      <td>36119</td>\n",
       "      <td>Westchester County</td>\n",
       "      <td>NY</td>\n",
       "      <td>7875</td>\n",
       "      <td>3/28/20</td>\n",
       "      <td>81.394844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1903</th>\n",
       "      <td>36081</td>\n",
       "      <td>Queens County</td>\n",
       "      <td>NY</td>\n",
       "      <td>10737</td>\n",
       "      <td>3/29/20</td>\n",
       "      <td>47.638316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922</th>\n",
       "      <td>36119</td>\n",
       "      <td>Westchester County</td>\n",
       "      <td>NY</td>\n",
       "      <td>8519</td>\n",
       "      <td>3/29/20</td>\n",
       "      <td>88.051134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1903</th>\n",
       "      <td>36081</td>\n",
       "      <td>Queens County</td>\n",
       "      <td>NY</td>\n",
       "      <td>12756</td>\n",
       "      <td>3/30/20</td>\n",
       "      <td>56.596290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922</th>\n",
       "      <td>36119</td>\n",
       "      <td>Westchester County</td>\n",
       "      <td>NY</td>\n",
       "      <td>9329</td>\n",
       "      <td>3/30/20</td>\n",
       "      <td>96.423175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1892</th>\n",
       "      <td>36059</td>\n",
       "      <td>Nassau County</td>\n",
       "      <td>NY</td>\n",
       "      <td>8544</td>\n",
       "      <td>3/31/20</td>\n",
       "      <td>62.965944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922</th>\n",
       "      <td>36119</td>\n",
       "      <td>Westchester County</td>\n",
       "      <td>NY</td>\n",
       "      <td>9967</td>\n",
       "      <td>3/31/20</td>\n",
       "      <td>103.017449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1892</th>\n",
       "      <td>36059</td>\n",
       "      <td>Nassau County</td>\n",
       "      <td>NY</td>\n",
       "      <td>9554</td>\n",
       "      <td>4/1/20</td>\n",
       "      <td>70.409249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922</th>\n",
       "      <td>36119</td>\n",
       "      <td>Westchester County</td>\n",
       "      <td>NY</td>\n",
       "      <td>10683</td>\n",
       "      <td>4/1/20</td>\n",
       "      <td>110.417920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922</th>\n",
       "      <td>36119</td>\n",
       "      <td>Westchester County</td>\n",
       "      <td>NY</td>\n",
       "      <td>11567</td>\n",
       "      <td>4/2/20</td>\n",
       "      <td>119.554814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922</th>\n",
       "      <td>36119</td>\n",
       "      <td>Westchester County</td>\n",
       "      <td>NY</td>\n",
       "      <td>12351</td>\n",
       "      <td>4/3/20</td>\n",
       "      <td>127.658123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922</th>\n",
       "      <td>36119</td>\n",
       "      <td>Westchester County</td>\n",
       "      <td>NY</td>\n",
       "      <td>13081</td>\n",
       "      <td>4/4/20</td>\n",
       "      <td>135.203296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1892</th>\n",
       "      <td>36059</td>\n",
       "      <td>Nassau County</td>\n",
       "      <td>NY</td>\n",
       "      <td>14398</td>\n",
       "      <td>4/5/20</td>\n",
       "      <td>106.107638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922</th>\n",
       "      <td>36119</td>\n",
       "      <td>Westchester County</td>\n",
       "      <td>NY</td>\n",
       "      <td>13723</td>\n",
       "      <td>4/5/20</td>\n",
       "      <td>141.838914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1892</th>\n",
       "      <td>36059</td>\n",
       "      <td>Nassau County</td>\n",
       "      <td>NY</td>\n",
       "      <td>18548</td>\n",
       "      <td>4/8/20</td>\n",
       "      <td>136.691517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1892</th>\n",
       "      <td>36059</td>\n",
       "      <td>Nassau County</td>\n",
       "      <td>NY</td>\n",
       "      <td>20140</td>\n",
       "      <td>4/9/20</td>\n",
       "      <td>148.423935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1892</th>\n",
       "      <td>36059</td>\n",
       "      <td>Nassau County</td>\n",
       "      <td>NY</td>\n",
       "      <td>21512</td>\n",
       "      <td>4/10/20</td>\n",
       "      <td>158.535040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1892</th>\n",
       "      <td>36059</td>\n",
       "      <td>Nassau County</td>\n",
       "      <td>NY</td>\n",
       "      <td>22584</td>\n",
       "      <td>4/11/20</td>\n",
       "      <td>166.435261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1892</th>\n",
       "      <td>36059</td>\n",
       "      <td>Nassau County</td>\n",
       "      <td>NY</td>\n",
       "      <td>23553</td>\n",
       "      <td>4/12/20</td>\n",
       "      <td>173.576413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1892</th>\n",
       "      <td>36059</td>\n",
       "      <td>Nassau County</td>\n",
       "      <td>NY</td>\n",
       "      <td>26715</td>\n",
       "      <td>4/15/20</td>\n",
       "      <td>196.879118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1892</th>\n",
       "      <td>36059</td>\n",
       "      <td>Nassau County</td>\n",
       "      <td>NY</td>\n",
       "      <td>27772</td>\n",
       "      <td>4/16/20</td>\n",
       "      <td>204.668795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1892</th>\n",
       "      <td>36059</td>\n",
       "      <td>Nassau County</td>\n",
       "      <td>NY</td>\n",
       "      <td>28539</td>\n",
       "      <td>4/17/20</td>\n",
       "      <td>210.321285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1892</th>\n",
       "      <td>36059</td>\n",
       "      <td>Nassau County</td>\n",
       "      <td>NY</td>\n",
       "      <td>29180</td>\n",
       "      <td>4/18/20</td>\n",
       "      <td>215.045205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       FIPS         County Name State  count     date        prev\n",
       "3019  53033         King County    WA      1  1/22/20    0.004439\n",
       "3019  53033         King County    WA      1  1/23/20    0.004439\n",
       "625   17031         Cook County    IL      1  1/24/20    0.001942\n",
       "3019  53033         King County    WA      1  1/24/20    0.004439\n",
       "625   17031         Cook County    IL      1  1/25/20    0.001942\n",
       "3019  53033         King County    WA      1  1/25/20    0.004439\n",
       "178   05125       Saline County    AR      4  1/27/20    0.326699\n",
       "235   06085  Santa Clara County    CA      2  1/29/20    0.010374\n",
       "235   06085  Santa Clara County    CA      2  1/30/20    0.010374\n",
       "235   06085  Santa Clara County    CA      2  1/31/20    0.010374\n",
       "625   17031         Cook County    IL      2  1/31/20    0.003883\n",
       "235   06085  Santa Clara County    CA      2   2/1/20    0.010374\n",
       "625   17031         Cook County    IL      2   2/1/20    0.003883\n",
       "235   06085  Santa Clara County    CA      2   2/2/20    0.010374\n",
       "625   17031         Cook County    IL      2   2/2/20    0.003883\n",
       "227   06069   San Benito County    CA      2   2/3/20    0.318431\n",
       "235   06085  Santa Clara County    CA      2   2/3/20    0.010374\n",
       "227   06069   San Benito County    CA      2   2/4/20    0.318431\n",
       "235   06085  Santa Clara County    CA      2   2/4/20    0.010374\n",
       "227   06069   San Benito County    CA      2   2/5/20    0.318431\n",
       "235   06085  Santa Clara County    CA      2   2/5/20    0.010374\n",
       "227   06069   San Benito County    CA      2   2/6/20    0.318431\n",
       "235   06085  Santa Clara County    CA      2   2/6/20    0.010374\n",
       "227   06069   San Benito County    CA      2   2/7/20    0.318431\n",
       "235   06085  Santa Clara County    CA      2   2/7/20    0.010374\n",
       "227   06069   San Benito County    CA      2   2/8/20    0.318431\n",
       "235   06085  Santa Clara County    CA      2   2/8/20    0.010374\n",
       "227   06069   San Benito County    CA      2   2/9/20    0.318431\n",
       "235   06085  Santa Clara County    CA      2   2/9/20    0.010374\n",
       "227   06069   San Benito County    CA      2  2/10/20    0.318431\n",
       "235   06085  Santa Clara County    CA      2  2/10/20    0.010374\n",
       "227   06069   San Benito County    CA      2  2/11/20    0.318431\n",
       "235   06085  Santa Clara County    CA      2  2/11/20    0.010374\n",
       "227   06069   San Benito County    CA      2  2/12/20    0.318431\n",
       "235   06085  Santa Clara County    CA      2  2/12/20    0.010374\n",
       "227   06069   San Benito County    CA      2  2/13/20    0.318431\n",
       "229   06073    San Diego County    CA      2  2/13/20    0.005991\n",
       "235   06085  Santa Clara County    CA      2  2/13/20    0.010374\n",
       "227   06069   San Benito County    CA      2  2/14/20    0.318431\n",
       "229   06073    San Diego County    CA      2  2/14/20    0.005991\n",
       "235   06085  Santa Clara County    CA      2  2/14/20    0.010374\n",
       "227   06069   San Benito County    CA      2  2/15/20    0.318431\n",
       "229   06073    San Diego County    CA      2  2/15/20    0.005991\n",
       "235   06085  Santa Clara County    CA      2  2/15/20    0.010374\n",
       "227   06069   San Benito County    CA      2  2/16/20    0.318431\n",
       "229   06073    San Diego County    CA      2  2/16/20    0.005991\n",
       "235   06085  Santa Clara County    CA      2  2/16/20    0.010374\n",
       "227   06069   San Benito County    CA      2  2/17/20    0.318431\n",
       "229   06073    San Diego County    CA      2  2/17/20    0.005991\n",
       "235   06085  Santa Clara County    CA      2  2/17/20    0.010374\n",
       "227   06069   San Benito County    CA      2  2/18/20    0.318431\n",
       "229   06073    San Diego County    CA      2  2/18/20    0.005991\n",
       "235   06085  Santa Clara County    CA      3  2/18/20    0.015561\n",
       "227   06069   San Benito County    CA      2  2/19/20    0.318431\n",
       "229   06073    San Diego County    CA      2  2/19/20    0.005991\n",
       "235   06085  Santa Clara County    CA      3  2/19/20    0.015561\n",
       "227   06069   San Benito County    CA      2  2/20/20    0.318431\n",
       "229   06073    San Diego County    CA      2  2/20/20    0.005991\n",
       "235   06085  Santa Clara County    CA      3  2/20/20    0.015561\n",
       "227   06069   San Benito County    CA      2  2/21/20    0.318431\n",
       "235   06085  Santa Clara County    CA      4  2/21/20    0.020748\n",
       "227   06069   San Benito County    CA      2  2/22/20    0.318431\n",
       "235   06085  Santa Clara County    CA      4  2/22/20    0.020748\n",
       "227   06069   San Benito County    CA      2  2/23/20    0.318431\n",
       "235   06085  Santa Clara County    CA      4  2/23/20    0.020748\n",
       "227   06069   San Benito County    CA      2  2/24/20    0.318431\n",
       "235   06085  Santa Clara County    CA      5  2/24/20    0.025936\n",
       "227   06069   San Benito County    CA      2  2/25/20    0.318431\n",
       "235   06085  Santa Clara County    CA      5  2/25/20    0.025936\n",
       "227   06069   San Benito County    CA      2  2/26/20    0.318431\n",
       "235   06085  Santa Clara County    CA      7  2/26/20    0.036310\n",
       "235   06085  Santa Clara County    CA      7  2/27/20    0.036310\n",
       "235   06085  Santa Clara County    CA      9  2/28/20    0.046684\n",
       "235   06085  Santa Clara County    CA     13  2/29/20    0.067433\n",
       "3019  53033         King County    WA      6  2/29/20    0.026634\n",
       "235   06085  Santa Clara County    CA     13   3/1/20    0.067433\n",
       "3019  53033         King County    WA      9   3/1/20    0.039951\n",
       "235   06085  Santa Clara County    CA     18   3/2/20    0.093368\n",
       "235   06085  Santa Clara County    CA     20   3/3/20    0.103742\n",
       "3019  53033         King County    WA     31   3/4/20    0.137608\n",
       "3019  53033         King County    WA     51   3/5/20    0.226387\n",
       "3033  53061    Snohomish County    WA     18   3/5/20    0.218956\n",
       "3019  53033         King County    WA     58   3/6/20    0.257459\n",
       "1922  36119  Westchester County    NY     57   3/7/20    0.589144\n",
       "3033  53061    Snohomish County    WA     27   3/7/20    0.328434\n",
       "1922  36119  Westchester County    NY     83   3/8/20    0.857876\n",
       "3019  53033         King County    WA     83   3/8/20    0.368433\n",
       "3033  53061    Snohomish County    WA     31   3/8/20    0.377091\n",
       "1922  36119  Westchester County    NY     98   3/9/20    1.012914\n",
       "1922  36119  Westchester County    NY    108  3/10/20    1.116272\n",
       "1922  36119  Westchester County    NY    121  3/11/20    1.250638\n",
       "1922  36119  Westchester County    NY    380  3/17/20    3.927624\n",
       "1922  36119  Westchester County    NY    538  3/18/20    5.560689\n",
       "1922  36119  Westchester County    NY    798  3/19/20    8.248011\n",
       "1922  36119  Westchester County    NY   1091  3/20/20   11.276416\n",
       "1893  36061     New York County    NY   1863  3/21/20   11.438529\n",
       "1922  36119  Westchester County    NY   1385  3/21/20   14.315157\n",
       "1892  36059       Nassau County    NY   1900  3/22/20   14.002258\n",
       "1922  36119  Westchester County    NY   2894  3/23/20   29.911959\n",
       "1922  36119  Westchester County    NY   3891  3/24/20   40.216805\n",
       "1903  36081       Queens County    NY   6420  3/25/20   28.484492\n",
       "1922  36119  Westchester County    NY   4691  3/25/20   48.485487\n",
       "1903  36081       Queens County    NY   7362  3/26/20   32.663992\n",
       "1922  36119  Westchester County    NY   5944  3/26/20   61.436312\n",
       "1922  36119  Westchester County    NY   7187  3/27/20   74.283777\n",
       "1922  36119  Westchester County    NY   7875  3/28/20   81.394844\n",
       "1903  36081       Queens County    NY  10737  3/29/20   47.638316\n",
       "1922  36119  Westchester County    NY   8519  3/29/20   88.051134\n",
       "1903  36081       Queens County    NY  12756  3/30/20   56.596290\n",
       "1922  36119  Westchester County    NY   9329  3/30/20   96.423175\n",
       "1892  36059       Nassau County    NY   8544  3/31/20   62.965944\n",
       "1922  36119  Westchester County    NY   9967  3/31/20  103.017449\n",
       "1892  36059       Nassau County    NY   9554   4/1/20   70.409249\n",
       "1922  36119  Westchester County    NY  10683   4/1/20  110.417920\n",
       "1922  36119  Westchester County    NY  11567   4/2/20  119.554814\n",
       "1922  36119  Westchester County    NY  12351   4/3/20  127.658123\n",
       "1922  36119  Westchester County    NY  13081   4/4/20  135.203296\n",
       "1892  36059       Nassau County    NY  14398   4/5/20  106.107638\n",
       "1922  36119  Westchester County    NY  13723   4/5/20  141.838914\n",
       "1892  36059       Nassau County    NY  18548   4/8/20  136.691517\n",
       "1892  36059       Nassau County    NY  20140   4/9/20  148.423935\n",
       "1892  36059       Nassau County    NY  21512  4/10/20  158.535040\n",
       "1892  36059       Nassau County    NY  22584  4/11/20  166.435261\n",
       "1892  36059       Nassau County    NY  23553  4/12/20  173.576413\n",
       "1892  36059       Nassau County    NY  26715  4/15/20  196.879118\n",
       "1892  36059       Nassau County    NY  27772  4/16/20  204.668795\n",
       "1892  36059       Nassau County    NY  28539  4/17/20  210.321285\n",
       "1892  36059       Nassau County    NY  29180  4/18/20  215.045205"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look over the time period and figure out what the epicenter was\n",
    "epis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "epi_dist_file = data_dir/'epi_dist.csv'\n",
    "if not epi_dist_file.exists():\n",
    "    # I haven't included sf12010countydistancemiles.csv in the repo beccause it's very large\n",
    "    # it is available for download here though: https://data.nber.org/data/county-distance-database.html\n",
    "    cty_dist = pd.read_csv(data_dir/'sf12010countydistancemiles.csv' )\n",
    "    cty_dist['county1'] = cty_dist['county1'].apply(lambda x: f'{int(x):05d}')\n",
    "    cty_dist['county2'] = cty_dist['county2'].apply(lambda x: f'{int(x):05d}')\n",
    "    epi_dist = cty_dist.loc[cty_dist.county1 == '36059', :]\n",
    "    epi_dist = epi_dist.rename(columns={'mi_to_county':'mi_to_epi', 'county2':'FIPS'})\n",
    "    epi_dist = epi_dist.drop('county1', axis=1)\n",
    "    epi_dist['FIPS'] = epi_dist.FIPS.apply(lambda x: f'{x:05d}')\n",
    "    epi_dist.to_csv(epi_dist_file, index=None)\n",
    "else:\n",
    "    epi_dist = pd.read_csv(epi_dist_file)\n",
    "    epi_dist['FIPS'] = epi_dist.FIPS.apply(lambda x: f'{x:05d}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.merge(epi_dist, how='left', on='FIPS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check test-retest response rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>n_participants</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample</th>\n",
       "      <th>n_responses</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Adult_UK_RT</th>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Adult_US_RT</th>\n",
       "      <th>1</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Parent_UK_RT</th>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Parent_US_RT</th>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          n_participants\n",
       "sample       n_responses                \n",
       "Adult_UK_RT  1                        23\n",
       "             2                        76\n",
       "Adult_US_RT  1                        26\n",
       "             2                        74\n",
       "Parent_UK_RT 1                        19\n",
       "             2                        75\n",
       "Parent_US_RT 1                        27\n",
       "             2                        67\n",
       "             3                         1"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dat.loc[dat['sample'].isin(rt_samples) & (~dat.exclude), :]\n",
    "    .groupby(['sample', 'participant_id'])[['timestamp1']]\n",
    "    .nunique()\n",
    "    .reset_index()\n",
    "    .groupby(['sample', 'timestamp1'])\n",
    "    .count()\n",
    "    .reset_index()\n",
    "    .rename(columns={'timestamp1':'n_responses','participant_id':'n_participants'})\n",
    "    .set_index(['sample', 'n_responses']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge covid data for UK\n",
    "## build uk data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "ukdat = dat.loc[~dat['sample'].str.contains('US'), :].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_cases = pd.read_csv( data_dir / 'covid-19-cases-uk.csv')\n",
    "eng_cases = pd.read_csv(data_dir / 'coronavirus-cases_uk.csv')\n",
    "eng_death = pd.read_csv(data_dir / 'coronavirus-deaths_uk.csv')\n",
    "eng_lut = pd.read_csv(data_dir / 'Lower_Tier_Local_Authority_to_Upper_Tier_Local_Authority_December_2018_Lookup_in_England_and_Wales_v2.csv')\n",
    "eng_region_lut = pd.read_csv(data_dir / 'Local_Authority_District_to_Region_December_2018_Lookup_in_England.csv')\n",
    "sco_lut = pd.read_csv(data_dir / 'ca2019_codes_and_labels_06042020_scotland.csv')\n",
    "wal_lut = pd.read_csv(data_dir / 'Unitary_Authority_to_Local_Health_Board_April_2019_Lookup_in_Wales.csv')\n",
    "uk_missing = pd.read_excel(data_dir / 'missing_uk_counties.xlsx')\n",
    "\n",
    "# Clean Fields\n",
    "for ix,row in uk_missing.iterrows():\n",
    "    ukdat.loc[ukdat.uid == row.uid, 'county'] = row.fixed_county\n",
    "\n",
    "ukdat['stateetc'] = ukdat.stateetc.str.lower().str.strip()\n",
    "ukdat['county'] = ukdat.county.str.lower().str.strip()\n",
    "ukdat['city'] = ukdat.city.str.lower().str.strip()\n",
    "ukdat['timestamp1'] = pd.to_datetime(ukdat.timestamp1)\n",
    "ukdat['date'] = ukdat.timestamp1.apply(lambda x: f'{x.date().month}/{x.date().day}/{x.date().year%2000}')\n",
    "# NI case data not available for 4/10-4/15,\n",
    "# I'm back filling with cases data from 4/15\n",
    "ni_date_shift_ids = ['5a384471e7bc8000010a8df2_06211', '5e3991cfd2bdfc030234b2b2_06329']\n",
    "ukdat.loc[ukdat.uid.isin(ni_date_shift_ids), 'date'] = '4/15/20'\n",
    "\n",
    "# Drop uk_cases data from before the earliest point of our data because\n",
    "# the whelsh data area changes\n",
    "uk_cases['Date'] = pd.to_datetime(uk_cases.Date)\n",
    "uk_cases = uk_cases.loc[(uk_cases.Date > (pd.to_datetime(ukdat.timestamp1).min()) - pd.to_timedelta('1 Day')), :]\n",
    "\n",
    "uk_cases['Area'] = uk_cases.Area.str.lower().str.strip()\n",
    "uk_cases.loc[uk_cases.TotalCases == '1 to 4', 'TotalCases']= 2.5\n",
    "uk_cases['TotalCases'] = uk_cases.TotalCases.astype(float)\n",
    "uk_cases['Date'] = pd.to_datetime(uk_cases['Date'])\n",
    "uk_cases['Date'] = uk_cases['Date'].apply(lambda x: f'{x.date().month}/{x.date().day}/{x.date().year%2000}')\n",
    "\n",
    "eng_cases['Area name'] = eng_cases['Area name'].str.lower().str.strip()\n",
    "eng_cases = eng_cases.rename(columns={'Area name': 'Area'})\n",
    "\n",
    "sco_lut['CAName'] = sco_lut.CAName.str.lower().str.strip()\n",
    "sco_lut['HBName'] = sco_lut.HBName.str.lower().str.strip()\n",
    "sco_lut['HBName'] = sco_lut.HBName.str.replace(' & ', ' and ')\n",
    "eng_lut['LTLA18NM'] = eng_lut.LTLA18NM.str.lower().str.strip()\n",
    "eng_lut['UTLA18NM'] = eng_lut.UTLA18NM.str.lower().str.strip()\n",
    "# Drop wales from the england lut\n",
    "eng_lut = eng_lut.loc[~(eng_lut.LTLA18CD.str[0] == 'W'), :]\n",
    "wal_lut['UA19NM'] = wal_lut.UA19NM.str.lower().str.strip()\n",
    "wal_lut['LHB19NM'] = wal_lut.LHB19NM.str.lower().str.strip()\n",
    "wal_lut['LHB19NM'] = wal_lut.LHB19NM.str.replace('health board', '').str.replace('university', '').str.replace('teaching', '').str.replace('morgannwg', '').str.strip()\n",
    "\n",
    "# Make sure luts are good\n",
    "assert len(sco_lut[~sco_lut.HBName.isin(uk_cases.Area)]) == 0\n",
    "assert len(wal_lut[~wal_lut.LHB19NM.isin(uk_cases.Area)]) == 0\n",
    "assert len(eng_lut[~eng_lut.UTLA18NM.isin(uk_cases.Area) & ~eng_lut.UTLA18NM.isin(wal_lut.UA19NM)]) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1222"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1739 - uk_missing.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "517"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uk_missing.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "ukdat['fixed_county'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1739\n",
      "591\n",
      "120\n"
     ]
    }
   ],
   "source": [
    "\n",
    "good_county_ind = ukdat.county.isin(uk_cases.Area)\n",
    "print(good_county_ind.sum())\n",
    "ukdat.loc[good_county_ind, 'fixed_county'] = ukdat.loc[good_county_ind, 'county']\n",
    "\n",
    "city_is_county = ukdat.city.isin(uk_cases.Area) & ukdat.fixed_county.isnull()\n",
    "print(city_is_county.sum())\n",
    "ukdat.loc[city_is_county, 'fixed_county'] = ukdat.loc[city_is_county, 'city']\n",
    "\n",
    "stateetc_is_county = ukdat.stateetc.isin(uk_cases.Area) & ukdat.fixed_county.isnull()\n",
    "print(stateetc_is_county.sum())\n",
    "ukdat.loc[stateetc_is_county, 'fixed_county'] = ukdat.loc[stateetc_is_county, 'stateetc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply luts\n",
    "eng_lut_county_ind = ukdat.county.isin(eng_lut.LTLA18NM) & ukdat.fixed_county.isnull()\n",
    "ukdat.loc[eng_lut_county_ind, 'fixed_county'] = ukdat.loc[eng_lut_county_ind, 'county'].apply(lambda x: eng_lut.loc[eng_lut.LTLA18NM == x, 'UTLA18NM'].values[0])\n",
    "\n",
    "eng_lut_city_ind = ukdat.city.isin(eng_lut.LTLA18NM) & ukdat.fixed_county.isnull()\n",
    "ukdat.loc[eng_lut_city_ind, 'fixed_county'] = ukdat.loc[eng_lut_city_ind, 'city'].apply(lambda x: eng_lut.loc[eng_lut.LTLA18NM == x, 'UTLA18NM'].values[0])\n",
    "\n",
    "eng_lut_stateetc_ind = ukdat.stateetc.isin(eng_lut.LTLA18NM) & ukdat.fixed_county.isnull()\n",
    "ukdat.loc[eng_lut_stateetc_ind, 'fixed_county'] = ukdat.loc[eng_lut_stateetc_ind, 'stateetc'].apply(lambda x: eng_lut.loc[eng_lut.LTLA18NM == x, 'UTLA18NM'].values[0])\n",
    "\n",
    "sco_lut_county_ind = ukdat.county.isin(sco_lut.CAName) & ukdat.fixed_county.isnull()\n",
    "ukdat.loc[sco_lut_county_ind, 'fixed_county'] = ukdat.loc[sco_lut_county_ind, 'county'].apply(lambda x: sco_lut.loc[sco_lut.CAName == x, 'HBName'].values[0])\n",
    "\n",
    "sco_lut_city_ind = ukdat.city.isin(sco_lut.CAName) & ukdat.fixed_county.isnull()\n",
    "ukdat.loc[sco_lut_city_ind, 'fixed_county'] = ukdat.loc[sco_lut_city_ind, 'city'].apply(lambda x: sco_lut.loc[sco_lut.CAName == x, 'HBName'].values[0])\n",
    "\n",
    "sco_lut_stateetc_ind = ukdat.stateetc.isin(sco_lut.CAName) & ukdat.fixed_county.isnull()\n",
    "ukdat.loc[sco_lut_stateetc_ind, 'fixed_county'] = ukdat.loc[sco_lut_stateetc_ind, 'stateetc'].apply(lambda x: sco_lut.loc[sco_lut.CAName == x, 'HBName'].values[0])\n",
    "\n",
    "wal_lut_county_ind = ukdat.county.isin(wal_lut.UA19NM) & ukdat.fixed_county.isnull()\n",
    "ukdat.loc[wal_lut_county_ind, 'fixed_county'] = ukdat.loc[wal_lut_county_ind, 'county'].apply(lambda x: wal_lut.loc[wal_lut.UA19NM == x, 'LHB19NM'].values[0])\n",
    "\n",
    "wal_lut_city_ind = ukdat.city.isin(wal_lut.UA19NM) & ukdat.fixed_county.isnull()\n",
    "ukdat.loc[wal_lut_city_ind, 'fixed_county'] = ukdat.loc[wal_lut_city_ind, 'city'].apply(lambda x: wal_lut.loc[wal_lut.UA19NM == x, 'LHB19NM'].values[0])\n",
    "\n",
    "wal_lut_stateetc_ind = ukdat.stateetc.isin(wal_lut.UA19NM) & ukdat.fixed_county.isnull()\n",
    "ukdat.loc[wal_lut_stateetc_ind, 'fixed_county'] = ukdat.loc[wal_lut_stateetc_ind, 'stateetc'].apply(lambda x: wal_lut.loc[wal_lut.UA19NM == x, 'LHB19NM'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2802\n"
     ]
    }
   ],
   "source": [
    "print(ukdat.fixed_county.notnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3303"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ukdat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "352"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2802 - (1739 + 591 + 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with https://coronavirus.data.gov.uk/#countries data first\n",
    "# Then unmatched stuff, merge with https://github.com/tomwhite/covid-19-uk-data/blob/master/data/covid-19-cases-uk.csv\n",
    "# Make merge table\n",
    "eng_cases['Specimen date'] = pd.to_datetime(eng_cases['Specimen date'])\n",
    "eng_cases['Specimen date'] = eng_cases['Specimen date'].apply(lambda x: f'{x.date().month}/{x.date().day}/{x.date().year%2000}')\n",
    "ec_to_merge = eng_cases.loc[eng_cases['Area type'] == 'Upper tier local authority', :]\n",
    "ec_to_merge = ec_to_merge.rename(columns={'Daily lab-confirmed cases':'new_local_cases',\n",
    "                                          'Cumulative lab-confirmed cases':'cumulative_local_cases',\n",
    "                                          'Specimen date': 'date',\n",
    "                                          'Area': 'county',\n",
    "                                          'Area code': 'area_code'})\n",
    "ec_to_merge = ec_to_merge.drop(['Area type'], axis=1)\n",
    "ec_to_merge['fixed_country'] = 'england'\n",
    "# do the merge\n",
    "ukdat = ukdat.merge(ec_to_merge, on=['county', 'date'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# make new cases variable\n",
    "uk_cases_date_shift = uk_cases.copy()\n",
    "uk_cases_date_shift['Date'] = (pd.to_datetime(uk_cases_date_shift.Date) + pd.to_timedelta('1 Day')).apply(lambda x: f'{x.date().month}/{x.date().day}/{x.date().year%2000}')\n",
    "uk_cases = uk_cases.merge(uk_cases_date_shift, how='left', on=['Date', 'Country', 'AreaCode', 'Area'], suffixes=['', '_prev'])\n",
    "uk_cases['new_local_cases'] = uk_cases.TotalCases - uk_cases.TotalCases_prev\n",
    "uk_cases['new_local_cases'] = uk_cases['new_local_cases'].fillna(0)\n",
    "uk_cases = uk_cases.drop('TotalCases_prev', axis=1)\n",
    "uk_cases['Country'] = uk_cases.Country.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make merge table\n",
    "uk_cases['Date'] = pd.to_datetime(uk_cases['Date'])\n",
    "uk_cases['Date'] = uk_cases['Date'].apply(lambda x: f'{x.date().month}/{x.date().day}/{x.date().year%2000}')\n",
    "ukc_to_merge = uk_cases.copy()\n",
    "ukc_to_merge = ukc_to_merge.rename(columns={'TotalCases': 'cumulative_local_cases',\n",
    "                                            'Date': 'date',\n",
    "                                            'Area': 'fixed_county',\n",
    "                                            'AreaCode': 'area_code',\n",
    "                                            'Country': 'fixed_country'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "ukdat = ukdat.merge(ukc_to_merge, on=['fixed_county', 'date'], how='left', suffixes=['', '_tomwhite'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "backfill_ind = (ukdat.cumulative_local_cases.isnull() & ukdat.cumulative_local_cases_tomwhite.notnull())\n",
    "ukdat.loc[backfill_ind, 'cumulative_local_cases'] = ukdat.loc[backfill_ind, 'cumulative_local_cases_tomwhite']\n",
    "ukdat.loc[backfill_ind, 'new_local_cases'] = ukdat.loc[backfill_ind, 'new_local_cases_tomwhite']\n",
    "ukdat.loc[backfill_ind, 'fixed_country'] = ukdat.loc[backfill_ind, 'fixed_country_tomwhite']\n",
    "ukdat.loc[backfill_ind, 'area_code'] = ukdat.loc[backfill_ind, 'area_code_tomwhite']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "ukdat['case_source'] = 'phe'\n",
    "ukdat.loc[backfill_ind, 'case_source'] = 'tomwhite'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure we've got data everywhere we should:\n",
    "assert len(ukdat[ukdat.fixed_county.notnull() & ukdat.area_code.isnull()]) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "501"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ukdat.fixed_county.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get region numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_lad_to_county = pd.read_csv(data_dir / 'Local_Authority_District_to_County_December_2018_Lookup_in_England.csv')\n",
    "eng_lad_to_county['LAD18NM'] = eng_lad_to_county.LAD18NM.str.lower().str.strip()\n",
    "eng_lad_to_county['CTY18NM'] = eng_lad_to_county.CTY18NM.str.lower().str.strip()\n",
    "eng_region_lut['LAD18NM'] = eng_region_lut.LAD18NM.str.lower().str.strip()\n",
    "eng_region_lut['RGN18NM'] = eng_region_lut.RGN18NM.str.lower().str.strip()\n",
    "\n",
    "# Add counties to region lookup\n",
    "eng_cty_to_rgn = eng_lad_to_county.merge(eng_region_lut, how='left', on=['LAD18CD', 'LAD18NM'], indicator=True, suffixes=('_x',''))\n",
    "\n",
    "# Each county is only in one reagoin\n",
    "assert (eng_cty_to_rgn.groupby('CTY18CD').RGN18CD.nunique() == 1).all()\n",
    "eng_cty_to_rgn = eng_cty_to_rgn.loc[:,['CTY18CD', 'CTY18NM', 'RGN18CD','RGN18NM', 'FID',]].groupby(['CTY18CD']).first().reset_index()\n",
    "eng_cty_to_rgn = eng_cty_to_rgn.rename(columns={'CTY18CD': 'LAD18CD', 'CTY18NM': 'LAD18NM'})\n",
    "eng_region_lut = eng_region_lut.append(eng_cty_to_rgn)\n",
    "eng_region_lut = eng_region_lut.rename(columns={'LAD18CD': 'area_code',\n",
    "                               'RGN18CD': 'region_code',\n",
    "                               'RGN18NM': 'fixed_region'})\n",
    "\n",
    "# all of the things with a fixed_country got a region that's in the region lut\n",
    "assert ((ukdat.fixed_country == 'england') & ~ukdat.area_code.isin(eng_region_lut.area_code)).sum() == 0\n",
    "\n",
    "ukdat = ukdat.merge(eng_region_lut.loc[:, ['area_code', 'region_code', 'fixed_region',]],\n",
    "                    how='left', on='area_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in regions for things that didn't match\n",
    "london_ind = ((ukdat.city.str.contains('london')\n",
    "              | ukdat.city.str.contains('londkn')\n",
    "              | ukdat.county.str.contains('london')\n",
    "              | ukdat.stateetc.str.contains('london'))\n",
    "              & ukdat.fixed_region.isnull())\n",
    "ukdat.loc[london_ind, 'fixed_region'] = 'london'\n",
    "ukdat.loc[london_ind, 'region_code'] = 'E12000007'\n",
    "\n",
    "nw_ind = ((ukdat.city.str.contains('manchester')\n",
    "           | ukdat.county.str.contains('manchester')\n",
    "           | ukdat.stateetc.str.contains('manchester')\n",
    "           | ukdat.stateetc.str.contains('north west'))\n",
    "           & ukdat.fixed_region.isnull())\n",
    "ukdat.loc[nw_ind, 'fixed_region'] = 'north west'\n",
    "ukdat.loc[nw_ind, 'region_code'] = 'E12000002'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_reg_cases = eng_cases.loc[eng_cases['Area type'] == 'Region', :].copy()\n",
    "eng_reg_cases = eng_reg_cases.rename(columns={'Daily lab-confirmed cases':'new_regional_cases',\n",
    "                                              'Cumulative lab-confirmed cases':'cumulative_regional_cases',\n",
    "                                              'Specimen date': 'date',\n",
    "                                              'Area code': 'region_code'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "ukdat = ukdat.merge(eng_reg_cases.loc[:, ['region_code', 'date', 'cumulative_regional_cases', 'new_regional_cases']],\n",
    "            on=['region_code', 'date'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_england_ind = (ukdat.fixed_country != 'england') & ukdat.fixed_county.notnull()\n",
    "ukdat.loc[not_england_ind, 'fixed_region'] = ukdat.loc[not_england_ind, 'fixed_county']\n",
    "ukdat.loc[not_england_ind, 'region_code'] = ukdat.loc[not_england_ind, 'area_code']\n",
    "ukdat.loc[not_england_ind, 'new_regional_cases'] = ukdat.loc[not_england_ind, 'new_local_cases']\n",
    "ukdat.loc[not_england_ind, 'cumulative_regional_cases'] = ukdat.loc[not_england_ind, 'cumulative_local_cases']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make sure that region merges in all but 40 cases\n",
    "assert len(ukdat.loc[ukdat.fixed_region.isnull()  & ~ukdat.exclude]) == 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "ukpop= pd.read_csv(data_dir / 'uk_population.csv', skiprows=9, names=['area', 'area_code', 'population'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "ukpop = ukpop.drop_duplicates(['area_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['wales', 'scotland'], dtype=object)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ukdat[ukdat.area_code.notnull() & ~ukdat.area_code.isin(ukpop.area_code)].fixed_country.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sco_pop = sco_lut.merge(ukpop, how='left',left_on='CA', right_on='area_code')\n",
    "sco_pop = sco_pop.groupby(['HBName', 'HB'])[['population']].sum().reset_index()\n",
    "sco_pop = sco_pop.rename(columns={'HB': 'area_code', 'HBName': 'area',})\n",
    "ukpop = ukpop.append(sco_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wal_pop = wal_lut.merge(ukpop, how='left',left_on='UA19CD', right_on='area_code')\n",
    "wal_pop = wal_pop.groupby(['LHB19NM', 'LHB19CD'])[['population']].sum().reset_index()\n",
    "wal_pop = wal_pop.rename(columns={'LHB19CD': 'area_code', 'LHB19NM': 'area',})\n",
    "ukpop = ukpop.append(wal_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "ukdat = ukdat.merge(ukpop.loc[:, ['area_code', 'population']], how='left', on='area_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "ukdat = ukdat.merge(ukpop.loc[:, ['area_code', 'population']], how='left', left_on='region_code', right_on='area_code', suffixes=['', '_region'])\n",
    "ukdat = ukdat.drop('area_code_region', axis=1)\n",
    "ukdat = ukdat.rename(columns = {\"population_region\":\"region_population\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "ukdat['cumulative_local_cases_per_10000'] = (ukdat.cumulative_local_cases / ukdat.population) * 10000\n",
    "ukdat['new_local_cases_per_10000'] = (ukdat.new_local_cases / ukdat.population) * 10000\n",
    "ukdat['cumulative_regional_cases_per_10000'] = (ukdat.cumulative_regional_cases / ukdat.region_population) * 10000\n",
    "ukdat['new_regional_cases_per_10000'] = (ukdat.new_regional_cases / ukdat.region_population) * 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11f258220>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(ukdat.loc[ukdat.cumulative_local_cases_per_10000.notnull()].cumulative_local_cases_per_10000, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save out datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "ukdat = ukdat.drop(ukdat.columns[ukdat.columns.str.contains('tomwhite')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fixed_county', 'area_code', 'cumulative_local_cases', 'fixed_country',\n",
       "       'case_source', 'region_code', 'fixed_region',\n",
       "       'cumulative_regional_cases', 'new_regional_cases', 'region_population',\n",
       "       'cumulative_local_cases_per_10000',\n",
       "       'cumulative_regional_cases_per_10000', 'new_regional_cases_per_10000'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ukdat.columns[~ukdat.columns.isin(merged_df)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using USAFacts data instead of Johns Hopkins as default\n",
    "jhu_cols = sorted(merged_df.columns[(merged_df.columns.str.contains('case') | merged_df.columns.str.contains('death')) & ~merged_df.columns.str.contains('_usf')])\n",
    "usf_cols = sorted(merged_df.columns[(merged_df.columns.str.contains('case') | merged_df.columns.str.contains('death')) & merged_df.columns.str.contains('_usf')])\n",
    "\n",
    "rn_dict = {jc:jc + '_jhu' for jc in jhu_cols}\n",
    "rn_dict.update({uc:uc[:-4]  for uc in usf_cols})\n",
    "merged_df = merged_df.rename(columns=rn_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "ukdat = ukdat.rename(columns={'cumulative_local_cases':'total_local_cases',\n",
    "                              'cumulative_regional_cases': 'total_stateetc_cases',\n",
    "                              'region_population': 'population_stateetc',\n",
    "                              'cumulative_local_cases_per_10000': 'total_local_cases_per_10000',\n",
    "                              'cumulative_regional_cases_per_10000': 'total_stateetc_cases_per_10000',\n",
    "                              'new_regional_cases_per_10000': 'new_stateetc_cases_per_10000',\n",
    "                              'new_regional_cases': 'new_stateetc_cases',\n",
    "                              'region_code': 'stateetc_code'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.rename(columns={'FIPS':'area_code',\n",
    "                                      'stateFIPS': 'stateetc_code'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_hold_out = merged_df.loc[merged_df.participant_id.isin(heldout_ids) & ~merged_df.participant_id.isin(rt_dat), :]\n",
    "us_working = merged_df.loc[~merged_df.participant_id.isin(heldout_ids) | merged_df.participant_id.isin(rt_dat), :]\n",
    "uk_hold_out = ukdat.loc[ukdat.participant_id.isin(heldout_ids) & ~ukdat.participant_id.isin(rt_dat), :]\n",
    "uk_working = ukdat.loc[~ukdat.participant_id.isin(heldout_ids) | ukdat.participant_id.isin(rt_dat), :]\n",
    "hold_out = pd.concat([us_hold_out, uk_hold_out], sort=False, )\n",
    "working = pd.concat([us_working, uk_working], sort=False)\n",
    "# Make sure everything's got the correct lengths\n",
    "assert hold_out.loc[~hold_out.exclude, :].participant_id.nunique() + working.loc[~working.exclude, :].participant_id.nunique() == dat.loc[~dat.exclude,:].participant_id.nunique() \n",
    "assert (len(hold_out) + len(working)) == len(dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nielsond/code/CRISIS_project/bright_boffin/env/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3062: DtypeWarning: Columns (39,238,260,288,289,290,291) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "# make sure hold-out split is preserved\n",
    "assert xp_dat.participant_id.isin(hold_out.participant_id).sum() == 0\n",
    "old_working = pd.read_csv(data_dir / 'working_data_20200424.csv')\n",
    "assert working.participant_id.isin(old_working.participant_id).all()\n",
    "assert old_working.participant_id.isin(working.participant_id).all()\n",
    "old_hold_out = pd.read_csv(data_dir / 'hold_out_data_20200424.csv')\n",
    "assert hold_out.participant_id.isin(old_hold_out.participant_id).all()\n",
    "assert old_hold_out.participant_id.isin(hold_out.participant_id).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>form</th>\n",
       "      <th>sample_country</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">adult</th>\n",
       "      <th>UK</th>\n",
       "      <td>930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US</th>\n",
       "      <td>902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">parent</th>\n",
       "      <th>UK</th>\n",
       "      <td>868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US</th>\n",
       "      <td>662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       participant_id\n",
       "form   sample_country                \n",
       "adult  UK                         930\n",
       "       US                         902\n",
       "parent UK                         868\n",
       "       US                         662"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "working.loc[~working.exclude & ~working['sample'].isin(rt_samples)].groupby(['form', 'sample_country'])[['participant_id']].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>n_participants</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>form</th>\n",
       "      <th>sample_country</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">adult</th>\n",
       "      <th>UK</th>\n",
       "      <td>1037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US</th>\n",
       "      <td>1017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">parent</th>\n",
       "      <th>UK</th>\n",
       "      <td>969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US</th>\n",
       "      <td>770</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       n_participants\n",
       "form   sample_country                \n",
       "adult  UK                        1037\n",
       "       US                        1017\n",
       "parent UK                         969\n",
       "       US                         770"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "working.loc[~working.exclude_with_RT].groupby(['form', 'sample_country'])[['participant_id']].nunique().rename(columns={'participant_id': 'n_participants'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_hold_out.to_csv(data_dir / 'us_hold_out_data_20200504.csv', index=None)\n",
    "us_working.to_csv(data_dir / 'us_working_data_20200504.csv', index=None)\n",
    "uk_hold_out.to_csv(data_dir / 'uk_hold_out_data_20200504.csv', index=None)\n",
    "uk_working.to_csv(data_dir / 'uk_working_data_20200504.csv', index=None)\n",
    "hold_out.to_csv(data_dir / 'hold_out_data_20200504.csv', index=None)\n",
    "working.to_csv(data_dir / 'working_data_20200504.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
